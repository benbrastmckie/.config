# Fix Failing Tests Implementation Plan

## Metadata
- **Date**: 2025-11-13
- **Feature**: Systematic fix of 17 failing tests in .claude/tests directory
- **Scope**: Test infrastructure repairs, library fixes, documentation updates
- **Estimated Phases**: 6
- **Standards File**: /home/benjamin/.config/CLAUDE.md
- **Total Failing Tests**: 17

## Overview

This plan addresses systematic failures across the test suite, organized by root cause. The failures fall into 6 categories affecting 17 test files. Each phase tackles one root cause category with verification testing after fixes.

**Failing Tests Summary**:
1. test_all_delegation_fixes
2. test_all_fixes_integration
3. test_bash_command_fixes
4. test_coordinate_all
5. test_coordinate_critical_bugs
6. test_coordinate_error_fixes
7. test_coordinate_preprocessing
8. test_coordinate_research_complexity_fix
9. test_coordinate_standards
10. test_coordinate_synchronization
11. test_coordinate_waves
12. test_orchestrate_planning_behavioral_injection
13. test_orchestrate_research_enhancements_simple
14. test_orchestration_commands
15. test_phase3_verification
16. test_revision_specialist
17. test_concurrent_workflows

## Success Criteria
- [ ] All 17 failing tests pass
- [ ] Test suite runs without errors
- [ ] No regression in previously passing tests
- [ ] Test environment setup standardized across all test files
- [ ] Libraries properly sourced in all commands
- [ ] Documentation updated for all missing sections

## Technical Analysis

### Root Cause Categories

1. **Environment Initialization** (affects 8+ tests)
   - Missing CLAUDE_PROJECT_DIR setup
   - Incorrect relative path assumptions

2. **Library Patterns** (affects 1 test)
   - Expected nameref pattern missing in workflow-initialization.sh

3. **Library Sourcing** (affects 3 tests)
   - unified-logger.sh not sourced in coordinate.md
   - dependency-analyzer.sh not sourced in coordinate.md
   - Missing graceful degradation patterns

4. **Documentation Gaps** (affects 5 tests)
   - orchestrate.md missing multiple documentation sections
   - Summary templates incomplete

5. **Test Assertions** (affects 3+ tests)
   - Tests checking for patterns that may not exist
   - Tests with incorrect expectations

6. **Concurrent Execution** (affects 1 test)
   - Test environment conflicts

## Implementation Phases

### Phase 1: Fix Test Environment Initialization
**Objective**: Standardize CLAUDE_PROJECT_DIR initialization across all test files
**Complexity**: Low
**Estimated Time**: 30 minutes

Tasks:
- [ ] Identify all test files that source libraries directly (.claude/lib/*.sh)
- [ ] Create standard test initialization template:
  ```bash
  #!/usr/bin/env bash
  set -euo pipefail

  # Standard test initialization
  if [ -z "${CLAUDE_PROJECT_DIR:-}" ]; then
    CLAUDE_PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
    export CLAUDE_PROJECT_DIR
  fi
  ```
- [ ] Add initialization block to test_coordinate_critical_bugs.sh
- [ ] Add initialization block to test_coordinate_research_complexity_fix.sh
- [ ] Add initialization block to any other test files that source libraries
- [ ] Update test paths to use absolute paths via CLAUDE_PROJECT_DIR
- [ ] Verify all library source statements use ${CLAUDE_PROJECT_DIR} prefix

Testing:
```bash
# Test files individually
bash .claude/tests/test_coordinate_critical_bugs.sh
bash .claude/tests/test_coordinate_research_complexity_fix.sh

# Run subset of affected tests
for test in test_coordinate_*.sh; do
  echo "Testing: $test"
  bash "$test" && echo "✓" || echo "✗"
done
```

Expected Outcomes:
- No "unbound variable" errors
- No "No such file or directory" errors for library files
- Tests can find and source required libraries

---

### Phase 2: Add unified-logger.sh Sourcing to coordinate.md
**Objective**: Fix emit_progress availability and add fallback patterns
**Complexity**: Low
**Estimated Time**: 20 minutes

Tasks:
- [ ] Read coordinate.md Phase 0 Block 3 (around line 100-200)
- [ ] Add unified-logger.sh sourcing after state-persistence.sh:
  ```bash
  # Source unified logger for emit_progress function
  if [ -f "${LIB_DIR}/unified-logger.sh" ]; then
    source "${LIB_DIR}/unified-logger.sh"
  fi
  ```
- [ ] Add fallback pattern for emit_progress calls:
  ```bash
  if command -v emit_progress &>/dev/null; then
    emit_progress "1" "State: Research (parallel agent invocation)"
  else
    echo "PROGRESS: [Phase 1] - State: Research (parallel agent invocation)"
  fi
  ```
- [ ] Apply fallback pattern to all emit_progress calls in coordinate.md
- [ ] Update test_bash_command_fixes.sh to verify fallback pattern exists

Testing:
```bash
# Test bash command fixes
bash .claude/tests/test_bash_command_fixes.sh

# Verify emit_progress function available
grep -c "command -v emit_progress" .claude/commands/coordinate.md
# Should be >= 5

# Verify fallback pattern exists
grep -c 'echo "PROGRESS:' .claude/commands/coordinate.md
# Should be >= 5
```

Expected Outcomes:
- test_bash_command_fixes.sh passes Test 3 (unified-logger.sh sourcing)
- test_bash_command_fixes.sh passes Test 4 (fallback pattern)
- emit_progress function available in all coordinate.md phases

---

### Phase 3: Verify and Fix nameref Pattern in workflow-initialization.sh
**Objective**: Determine if nameref pattern is required; update library or test
**Complexity**: Medium
**Estimated Time**: 30 minutes

Tasks:
- [ ] Read workflow-initialization.sh to check current variable passing patterns
- [ ] Identify functions using indirect variable expansion (${!var})
- [ ] Research: Check if nameref (local -n) is required for bash compatibility
- [ ] **Decision Point**:
  - If nameref improves code → Add `local -n` pattern to functions
  - If current pattern works → Update test expectation
- [ ] If adding nameref:
  - [ ] Convert indirect expansions to nameref pattern:
    ```bash
    # Old pattern
    local var_name="$1"
    local value="${!var_name}"

    # New pattern (nameref)
    local -n var_ref="$1"
    local value="$var_ref"
    ```
  - [ ] Test library sources cleanly
- [ ] If updating test:
  - [ ] Modify test_bash_command_fixes.sh Test 1 to remove nameref requirement
  - [ ] Document why nameref not required in test comments

Testing:
```bash
# Test library sources without errors
bash -c "source .claude/lib/workflow-initialization.sh" 2>&1 | grep -i error
# Should have no output

# Test bash command fixes
bash .claude/tests/test_bash_command_fixes.sh

# Verify no breaking changes
bash .claude/tests/run_all_tests.sh 2>&1 | grep workflow-initialization
```

Expected Outcomes:
- test_bash_command_fixes.sh Test 1 passes
- workflow-initialization.sh sources cleanly
- No regressions in other tests using workflow-initialization.sh

---

### Phase 4: Add dependency-analyzer.sh Sourcing to coordinate.md
**Objective**: Enable wave execution by sourcing required library
**Complexity**: Low
**Estimated Time**: 15 minutes

Tasks:
- [ ] Check if dependency-analyzer.sh is in REQUIRED_LIBS array for full-implementation scope
- [ ] Verify dependency-analyzer.sh exists at .claude/lib/dependency-analyzer.sh
- [ ] Add to REQUIRED_LIBS in coordinate.md for full-implementation scope:
  ```bash
  full-implementation)
    REQUIRED_LIBS=("workflow-detection.sh" "workflow-scope-detection.sh"
                   "unified-logger.sh" "unified-location-detection.sh"
                   "overview-synthesis.sh" "metadata-extraction.sh"
                   "checkpoint-utils.sh" "dependency-analyzer.sh"
                   "context-pruning.sh" "error-handling.sh")
    ;;
  ```
- [ ] Verify library sourced by checking source_required_libraries function
- [ ] Update test_coordinate_all.sh if it checks for direct source statement

Testing:
```bash
# Test coordinate_all wave execution tests
bash .claude/tests/test_coordinate_all.sh 2>&1 | grep -A 5 "Wave Execution"

# Verify dependency-analyzer available in coordinate workflow
grep -A 10 "full-implementation)" .claude/commands/coordinate.md | grep dependency-analyzer

# Run full test
bash .claude/tests/test_coordinate_all.sh
```

Expected Outcomes:
- test_coordinate_all.sh Wave Execution Tests pass
- dependency-analyzer.sh sourced for full-implementation workflows
- Wave-based parallel execution works correctly

---

### Phase 5: Add Missing Documentation to orchestrate.md
**Objective**: Complete documentation gaps for orchestrate planning tests
**Complexity**: Medium
**Estimated Time**: 45 minutes

Tasks:
- [ ] Read test_orchestrate_planning_behavioral_injection.sh to identify all expected documentation
- [ ] Add topic-based path format documentation to orchestrate.md Phase 2:
  ```markdown
  ### Path Calculation

  Plans are created using topic-based structure:
  - Format: `specs/{NNN_topic}/plans/{NNN}_plan_name.md`
  - Topic number: Auto-incremented from highest existing
  - Topic name: Sanitized from workflow description
  - Plan number: Sequential within topic directory
  ```
- [ ] Add research report cross-reference passing documentation:
  ```markdown
  ### Research Integration

  Plan architect receives:
  - Array of research report paths: REPORT_PATHS[@]
  - Report metadata extraction for context reduction
  - Cross-reference requirement in agent prompt
  ```
- [ ] Add metadata extraction strategy documentation:
  ```markdown
  ### Context Reduction Strategy

  Hierarchical metadata extraction:
  1. Research reports → Title + 50-word summary (99% reduction)
  2. Plan metadata → Complexity score + phase count
  3. Forward message pattern → Pass subagent output directly
  ```
- [ ] Add summary template artifact sections:
  ```markdown
  ## Artifacts Generated

  ### Research Reports
  - Report 1: [path] ([size])
  - Report 2: [path] ([size])

  ### Implementation Plan
  - Path: [plan_path]
  - Phases: [count]
  - Complexity: [score]
  ```
- [ ] Update orchestrate.md Phase 2 (Planning) with all documentation sections
- [ ] Verify cross-references between orchestrate.md and workflow-phases.md

Testing:
```bash
# Test orchestrate planning behavioral injection
bash .claude/tests/test_orchestrate_planning_behavioral_injection.sh

# Test all delegation fixes
bash .claude/tests/test_all_delegation_fixes.sh

# Verify documentation present
grep -c "topic-based structure" .claude/commands/orchestrate.md
grep -c "Research Integration" .claude/commands/orchestrate.md
grep -c "Context Reduction Strategy" .claude/commands/orchestrate.md
grep -c "Artifacts Generated" .claude/commands/orchestrate.md
```

Expected Outcomes:
- test_orchestrate_planning_behavioral_injection.sh passes all tests
- test_all_delegation_fixes.sh passes orchestrate documentation tests
- All required documentation sections present in orchestrate.md
- Summary template includes artifact tracking

---

### Phase 6: Fix Remaining Test Assertion Issues
**Objective**: Fix tests with incorrect expectations or environmental issues
**Complexity**: Medium
**Estimated Time**: 60 minutes

Tasks:
- [ ] Run each remaining failing test individually to diagnose
- [ ] test_phase3_verification - Check verify_state_variables function:
  - [ ] Review test expectations vs actual function behavior
  - [ ] Fix test assertions if function works correctly
  - [ ] Fix function if test expectations are correct
- [ ] test_revision_specialist - Check workflow scope detection:
  - [ ] Verify research-and-revise pattern detection works
  - [ ] Fix regex pattern if detection fails
  - [ ] Update test if expectations incorrect
- [ ] test_concurrent_workflows - Check for test isolation issues:
  - [ ] Verify tests use unique temporary files
  - [ ] Add cleanup between test runs
  - [ ] Fix any shared state issues
- [ ] test_coordinate_error_fixes - Check error handling:
  - [ ] Verify error handling functions exist
  - [ ] Update tests to match current error handling implementation
- [ ] test_coordinate_preprocessing - Check preprocessing patterns:
  - [ ] Verify set +H (disable history expansion) present
  - [ ] Check for proper quoting in all bash blocks
- [ ] test_coordinate_standards - Check standards compliance:
  - [ ] Verify coordinate.md follows Standard 11 (Imperative Agent Invocation)
  - [ ] Check Standard 15 (Library Sourcing Order) compliance
- [ ] test_coordinate_synchronization - Check state synchronization:
  - [ ] Verify append_workflow_state calls present
  - [ ] Check load_workflow_state in each bash block
- [ ] test_coordinate_waves - Check wave execution patterns:
  - [ ] Verify dependency analysis integration
  - [ ] Check parallel execution documentation
- [ ] test_orchestration_commands - Check all orchestration commands:
  - [ ] Run validation for /coordinate, /orchestrate, /supervise
  - [ ] Fix any command-specific issues

Testing:
```bash
# Test each remaining test individually
for test in test_phase3_verification test_revision_specialist test_concurrent_workflows test_coordinate_error_fixes test_coordinate_preprocessing test_coordinate_standards test_coordinate_synchronization test_coordinate_waves test_orchestration_commands test_all_fixes_integration; do
  echo "=== Testing: $test ==="
  bash .claude/tests/${test}.sh 2>&1 | tail -20
  echo ""
done

# Run full test suite
bash .claude/tests/run_all_tests.sh 2>&1 | tail -100
```

Expected Outcomes:
- All 17 failing tests now pass
- No new test failures introduced
- Test suite summary shows 0 failed tests
- All test categories green

---

## Final Verification

After completing all phases:

```bash
# Run complete test suite
cd /home/benjamin/.config/.claude/tests
bash run_all_tests.sh 2>&1 | tee /tmp/final_test_run.txt

# Check final summary
tail -50 /tmp/final_test_run.txt

# Verify zero failures
grep "Suites Failed:" /tmp/final_test_run.txt | grep "0"

# List any remaining failures
grep "✗.*FAILED" /tmp/final_test_run.txt || echo "All tests pass!"
```

## Testing Strategy

### Per-Phase Testing
- Run affected tests after each phase
- Verify no regressions in related tests
- Check error messages are clear and actionable

### Integration Testing
- Run full test suite after Phase 3 and Phase 6
- Verify test execution time reasonable (<5 minutes)
- Check for any test interdependencies

### Regression Testing
- Compare test pass/fail counts before and after
- Ensure previously passing tests still pass
- Monitor for new failure patterns

## Documentation Requirements

- [ ] Update test README if test initialization pattern changed
- [ ] Document standard test initialization block in testing protocols
- [ ] Update coordinate-command-guide.md with library sourcing changes
- [ ] Update orchestrate documentation as specified in Phase 5
- [ ] Add comments to any tests with modified assertions explaining why

## Dependencies

### External
- bash 4.0+ (for nameref support if used)
- jq (for JSON parsing in tests)
- grep with -P flag (Perl regex support)

### Internal Libraries
- workflow-state-machine.sh
- state-persistence.sh
- unified-logger.sh
- dependency-analyzer.sh
- workflow-initialization.sh
- All libraries in .claude/lib/

## Risk Assessment

### Low Risk
- Phases 1, 2, 4: Simple additions that don't change behavior
- Test environment fixes isolated to test files

### Medium Risk
- Phase 3: Nameref pattern change could affect library behavior
  - Mitigation: Test thoroughly before committing
  - Mitigation: Easy to revert if issues arise
- Phase 5: Documentation additions are non-functional
  - Mitigation: Only affects test expectations, not runtime

### High Risk
- Phase 6: Multiple tests with unknown root causes
  - Mitigation: Fix one test at a time
  - Mitigation: Run full suite between fixes
  - Mitigation: Document any behavioral changes

## Rollback Plan

Each phase is independent and can be rolled back individually:

1. **Phase 1**: Remove initialization blocks from test files
2. **Phase 2**: Remove unified-logger.sh sourcing and fallback patterns
3. **Phase 3**: Revert library changes or test changes
4. **Phase 4**: Remove dependency-analyzer.sh from REQUIRED_LIBS
5. **Phase 5**: Revert orchestrate.md documentation additions
6. **Phase 6**: Revert individual test changes

## Notes

### Test Infrastructure Improvements
After fixing all tests, consider:
- Creating shared test utilities library
- Standardizing test output format
- Adding test categories for selective execution
- Implementing test timeouts

### Potential Future Work
- Add pre-commit hook to run affected tests
- Create test coverage reporting
- Add performance benchmarks for slow tests
- Implement parallel test execution

### Known Limitations
- Some tests may be testing implementation details vs behavior
- Test assertions may need ongoing maintenance as code evolves
- Environment-specific issues may still occur on different systems
