# LLM Classification Agent Integration - Implementation Plan

## Metadata
- **Date**: 2025-11-14
- **Feature**: Replace file-based LLM classification with agent-based invocation
- **Scope**: Orchestration commands, state machine library, checkpoint schema
- **Estimated Phases**: 6
- **Total Effort**: ~5 hours
- **Standards File**: /home/benjamin/.config/CLAUDE.md
- **Research Reports**:
  - [OVERVIEW.md](../reports/001_llm_classification_state_machine_integration/OVERVIEW.md)
  - [001_agent_invocation_pattern_and_task_tool_integration.md](../reports/001_llm_classification_state_machine_integration/001_agent_invocation_pattern_and_task_tool_integration.md)
  - [002_state_machine_checkpoint_coordination_with_classification.md](../reports/001_llm_classification_state_machine_integration/002_state_machine_checkpoint_coordination_with_classification.md)
  - [003_command_level_classification_flow_and_error_handling.md](../reports/001_llm_classification_state_machine_integration/003_command_level_classification_flow_and_error_handling.md)
  - [004_backward_compatibility_and_library_migration_strategy.md](../reports/001_llm_classification_state_machine_integration/004_backward_compatibility_and_library_migration_strategy.md)

## Overview

Current LLM classification uses **file-based signaling** (`.claude/lib/workflow-llm-classifier.sh:287-359`) that emits `[LLM_CLASSIFICATION_REQUEST]` markers to stderr and polls for response files. No handler exists to process these requests, causing **100% timeout rate** (10 seconds wasted per workflow initialization).

This plan implements the proven **behavioral injection pattern** (Standard 11) by creating a workflow-classifier agent and invoking it from orchestration commands BEFORE state machine initialization. Classification results are passed to `sm_init()` as parameters, eliminating timeouts while maintaining fail-fast architecture.

**Design Philosophy**: Clean-break refactoring with NO backward compatibility concerns, prioritizing elegant state-machine integration over gradual migration.

## Success Criteria

- [ ] Zero classification timeouts across all orchestration commands
- [ ] Classification completes in <5 seconds (typically 3-4s with Haiku)
- [ ] All workflow types correctly classified (research-only, research-and-plan, full-implementation, debug-only)
- [ ] Classification metadata persisted in checkpoint schema v2.1
- [ ] Complete workflow resumability with classification preservation
- [ ] File-based signaling code removed (clean-break)
- [ ] No compatibility shims or deprecated code paths

## Technical Design

### Architecture

**Clean Separation of Concerns**:
```
Command Level (Task tool available)
    ↓
  Agent Invocation → workflow-classifier.md
    ↓
  Classification Result (JSON)
    ↓
  State Machine Init → sm_init(desc, cmd, classification)
    ↓
  Checkpoint Save (includes classification metadata)
```

### Key Design Decisions

**Decision 1: Command-Level Classification (Not Library-Level)**

**Rationale**:
- Libraries cannot use Task tool (requires command execution context)
- Commands orchestrate, agents execute, libraries provide utilities (architectural separation)
- Proven pattern: All existing agent invocations occur in commands
- Fail-fast: Classification failures visible immediately at command level

**Decision 2: No Backward Compatibility**

**Rationale**:
- File-based signaling never worked (no handler implemented)
- Clean-break philosophy prioritizes quality over compatibility
- All three orchestration commands updated simultaneously
- No transition period needed (single atomic change)

**Decision 3: Mandatory Classification Parameters**

**Rationale**:
- Eliminates dual-path complexity in `sm_init()`
- Forces explicit classification (fail-fast if missing)
- Makes dependencies obvious (command must classify before init)
- Reduces cognitive load (one way to initialize state machine)

**Decision 4: Checkpoint Schema v2.1 with Classification Section**

**Rationale**:
- Classification results critical for workflow resume
- Terminal state calculation depends on workflow_type
- Research phase allocation depends on research_complexity
- Atomic coordination between state files and checkpoints

### Data Flow

**Phase 0: Workflow Classification** (before state machine):
1. Command saves workflow description to bash variable
2. Command invokes workflow-classifier agent via Task tool
3. Agent returns JSON: `{workflow_type, confidence, research_complexity, research_topics}`
4. Command parses JSON and validates required fields
5. Command calls `sm_init()` with classification parameters

**State Machine Integration**:
```bash
# Refactored sm_init signature (clean-break)
sm_init() {
  local workflow_desc="$1"
  local command_name="$2"
  local workflow_type="$3"           # REQUIRED
  local research_complexity="$4"     # REQUIRED
  local research_topics_json="$5"    # REQUIRED

  # No classification invocation (already done at command level)
  # No dual-path logic (clean single implementation)

  # Store classification results
  WORKFLOW_SCOPE="$workflow_type"
  RESEARCH_COMPLEXITY="$research_complexity"
  RESEARCH_TOPICS_JSON="$research_topics_json"

  export WORKFLOW_SCOPE RESEARCH_COMPLEXITY RESEARCH_TOPICS_JSON

  # Calculate terminal state from workflow_type
  case "$WORKFLOW_SCOPE" in
    research-only) TERMINAL_STATE="$STATE_RESEARCH" ;;
    research-and-plan) TERMINAL_STATE="$STATE_PLAN" ;;
    full-implementation) TERMINAL_STATE="$STATE_COMPLETE" ;;
    debug-only) TERMINAL_STATE="$STATE_DEBUG" ;;
    *) echo "ERROR: Invalid workflow_type: $WORKFLOW_SCOPE" >&2; return 1 ;;
  esac

  sm_reset  # Initialize to STATE_INITIALIZE
  return 0
}
```

### Checkpoint Schema v2.1

**Extension to v2.0** (add classification section):
```json
{
  "schema_version": "2.1",
  "state_machine": {
    "current_state": "research",
    "completed_states": ["initialize"],
    "workflow_config": {
      "scope": "full-implementation",
      "description": "Add user authentication",
      "command": "coordinate"
    },
    "classification": {
      "workflow_type": "full-implementation",
      "research_complexity": 2,
      "research_topics": [
        {
          "short_name": "Authentication patterns",
          "detailed_description": "Analyze current authentication implementation",
          "filename_slug": "authentication_patterns",
          "research_focus": "Key questions: How is auth currently handled?"
        }
      ],
      "confidence": 0.95,
      "reasoning": "Workflow requires complete implementation cycle",
      "classified_at": "2025-11-14T14:30:00Z"
    }
  }
}
```

## Implementation Phases

### Phase 1: Create Workflow Classifier Agent

**Objective**: Create agent behavioral file following proven patterns (research-specialist.md).

**Complexity**: Low

**Tasks**:
- [ ] Create `.claude/agents/workflow-classifier.md` behavioral file
- [ ] Define classification rules with semantic analysis (not keyword matching)
- [ ] Add comprehensive examples covering edge cases:
  - Ambiguous descriptions: "research the research-and-revise workflow"
  - Negations: "don't revise, create new plan"
  - Quoted keywords: "research the 'implement' command"
  - Complex workflows: "research, plan, implement, test, debug"
- [ ] Specify JSON output schema matching library format:
  ```json
  {
    "workflow_type": "research-and-plan",
    "confidence": 0.95,
    "research_complexity": 2,
    "research_topics": [
      {
        "short_name": "...",
        "detailed_description": "...",
        "filename_slug": "...",
        "research_focus": "..."
      }
    ],
    "reasoning": "..."
  }
  ```
- [ ] Set model to `haiku` (fast, cost-effective for classification)
- [ ] Set `allowed-tools: None` (pure logic agent, no file access)
- [ ] Add validation rules:
  - Confidence must be 0.0-1.0
  - Research complexity must be 1-4
  - Topic count must match complexity
  - Filename slugs must match `^[a-z0-9_]{1,50}$`

**Testing**:
```bash
# Manual agent testing (outside implementation workflow)
# Test via Claude Code Task tool with sample descriptions
```

**Validation Criteria**:
- Agent returns valid JSON for all test cases
- Classification accuracy >95% (manually validated sample set)
- Response time <5 seconds (Haiku model)
- No tool invocations (pure logic)

**Files Created**:
- `.claude/agents/workflow-classifier.md` (~300 lines)

**Dependencies**: None

---

### Phase 2: Refactor sm_init() to Clean-Break Signature

**Objective**: Remove file-based classification from state machine, accept parameters only.

**Complexity**: Medium

**Tasks**:
- [ ] Update `sm_init()` signature in `.claude/lib/workflow-state-machine.sh:334-476`:
  - Change from: `sm_init(workflow_desc, command_name)`
  - Change to: `sm_init(workflow_desc, command_name, workflow_type, research_complexity, research_topics_json)`
- [ ] Remove classification invocation logic (lines 349-380):
  - Delete `classify_workflow_comprehensive()` call
  - Delete classification stderr file handling
  - Delete error handling for classification failure
- [ ] Add parameter validation with fail-fast:
  ```bash
  # Validate required parameters
  if [ -z "$workflow_type" ] || [ -z "$research_complexity" ] || [ -z "$research_topics_json" ]; then
    echo "ERROR: sm_init requires classification parameters" >&2
    echo "  Usage: sm_init WORKFLOW_DESC COMMAND_NAME WORKFLOW_TYPE RESEARCH_COMPLEXITY RESEARCH_TOPICS_JSON" >&2
    return 1
  fi

  # Validate workflow_type enum
  case "$workflow_type" in
    research-only|research-and-plan|research-and-revise|full-implementation|debug-only)
      : # Valid
      ;;
    *)
      echo "ERROR: Invalid workflow_type: $workflow_type" >&2
      return 1
      ;;
  esac

  # Validate research_complexity range
  if [ "$research_complexity" -lt 1 ] || [ "$research_complexity" -gt 4 ]; then
    echo "ERROR: research_complexity must be 1-4, got: $research_complexity" >&2
    return 1
  fi

  # Validate research_topics_json is valid JSON array
  if ! echo "$research_topics_json" | jq -e 'type == "array"' >/dev/null 2>&1; then
    echo "ERROR: research_topics_json must be valid JSON array" >&2
    return 1
  fi
  ```
- [ ] Update exports with validated parameters:
  ```bash
  WORKFLOW_SCOPE="$workflow_type"
  RESEARCH_COMPLEXITY="$research_complexity"
  RESEARCH_TOPICS_JSON="$research_topics_json"

  export WORKFLOW_SCOPE RESEARCH_COMPLEXITY RESEARCH_TOPICS_JSON
  ```
- [ ] Update terminal state calculation (no changes needed, uses WORKFLOW_SCOPE)
- [ ] Remove classification cleanup code (no temp files created)
- [ ] Update function docstring with new signature

**Testing**:
```bash
# Test new signature with valid parameters
source .claude/lib/workflow-state-machine.sh
sm_init "test description" "coordinate" "research-and-plan" 2 '[{"short_name":"topic1","detailed_description":"desc","filename_slug":"topic1","research_focus":"focus"}]'
echo "WORKFLOW_SCOPE=$WORKFLOW_SCOPE"
# Expected: WORKFLOW_SCOPE=research-and-plan

# Test fail-fast validation
sm_init "test" "coordinate" "invalid-type" 2 '[]'
# Expected: ERROR: Invalid workflow_type

sm_init "test" "coordinate" "research-only" 5 '[]'
# Expected: ERROR: research_complexity must be 1-4
```

**Validation Criteria**:
- Function fails fast on missing parameters
- Function fails fast on invalid workflow_type
- Function fails fast on invalid complexity range
- Function fails fast on malformed JSON
- Function succeeds with valid parameters
- All exports are set correctly

**Files Modified**:
- `.claude/lib/workflow-state-machine.sh` (lines 334-476, ~40 lines changed)

**Dependencies**: None

---

### Phase 3: Update /coordinate Command with Agent Invocation

**Objective**: Add Phase 0 classification agent invocation before sm_init().

**Complexity**: Medium

**Tasks**:
- [ ] Add Phase 0: Workflow Classification section before current sm_init call (`.claude/commands/coordinate.md:164-188`)
- [ ] Save workflow description to bash variable:
  ```bash
  # Save workflow description for agent invocation
  SAVED_WORKFLOW_DESC="$workflow_description"
  ```
- [ ] Add imperative agent invocation block (following Standard 11):
  ```markdown
  ## Phase 0: Workflow Classification

  **EXECUTE NOW**: USE the Task tool to invoke workflow-classifier agent:

  Task {
    subagent_type: "general-purpose"
    description: "Classify workflow intent for orchestration"
    timeout: 30000
    model: "haiku"
    prompt: "
      Read and follow ALL behavioral guidelines from:
      /home/benjamin/.config/.claude/agents/workflow-classifier.md

      **Workflow-Specific Context**:
      - Workflow Description: $SAVED_WORKFLOW_DESC
      - Command Name: coordinate

      **CRITICAL**: Return structured JSON classification.

      Execute classification following all guidelines in behavioral file.
      Return: CLASSIFICATION_COMPLETE: {JSON classification object}
    "
  }
  ```
- [ ] Add bash block to parse classification result:
  ```bash
  # Parse classification JSON from agent return
  if [ -z "$CLASSIFICATION_RESULT" ]; then
    echo ""
    echo "✗ ERROR: Classification agent did not return result"
    echo "   Expected: CLASSIFICATION_COMPLETE: {JSON}"
    echo "   Found: No CLASSIFICATION_RESULT variable"
    echo ""
    echo "Diagnostic commands:"
    echo "  echo \$CLASSIFICATION_RESULT"
    echo ""
    echo "Workflow terminated"
    exit 1
  fi

  # Extract classification dimensions with validation
  WORKFLOW_TYPE=$(echo "$CLASSIFICATION_RESULT" | jq -r '.workflow_type // empty')
  RESEARCH_COMPLEXITY=$(echo "$CLASSIFICATION_RESULT" | jq -r '.research_complexity // empty')
  RESEARCH_TOPICS_JSON=$(echo "$CLASSIFICATION_RESULT" | jq -c '.research_topics // empty')
  CLASSIFICATION_CONFIDENCE=$(echo "$CLASSIFICATION_RESULT" | jq -r '.confidence // 0.0')

  # Fail-fast validation
  if [ -z "$WORKFLOW_TYPE" ]; then
    echo "ERROR: Classification missing workflow_type" >&2
    exit 1
  fi

  if [ -z "$RESEARCH_COMPLEXITY" ]; then
    echo "ERROR: Classification missing research_complexity" >&2
    exit 1
  fi

  if [ -z "$RESEARCH_TOPICS_JSON" ] || [ "$RESEARCH_TOPICS_JSON" = "null" ]; then
    echo "ERROR: Classification missing research_topics" >&2
    exit 1
  fi

  # Log classification results
  echo "✓ Workflow classified:"
  echo "  Type: $WORKFLOW_TYPE"
  echo "  Complexity: $RESEARCH_COMPLEXITY"
  echo "  Confidence: $CLASSIFICATION_CONFIDENCE"
  echo "  Topics: $(echo "$RESEARCH_TOPICS_JSON" | jq -r '.[].short_name' | tr '\n' ', ' | sed 's/, $//')"
  echo ""
  ```
- [ ] Update sm_init call with classification parameters:
  ```bash
  # Initialize state machine with classification results
  sm_init "$SAVED_WORKFLOW_DESC" "coordinate" "$WORKFLOW_TYPE" "$RESEARCH_COMPLEXITY" "$RESEARCH_TOPICS_JSON"
  SM_INIT_EXIT_CODE=$?

  # Fail-fast on initialization error
  if [ $SM_INIT_EXIT_CODE -ne 0 ]; then
    echo ""
    echo "✗ ERROR: State machine initialization failed"
    echo "   Exit code: $SM_INIT_EXIT_CODE"
    echo ""
    echo "Diagnostic commands:"
    echo "  echo \$WORKFLOW_TYPE"
    echo "  echo \$RESEARCH_COMPLEXITY"
    echo "  echo \$RESEARCH_TOPICS_JSON"
    echo ""
    echo "Workflow terminated"
    exit 1
  fi
  ```
- [ ] Remove old classification error handling (line 170, no longer needed)
- [ ] Update Phase 0 initialization log to reflect classification happened earlier:
  ```bash
  echo "✓ State machine initialized (classification pre-computed)"
  ```

**Testing**:
```bash
# Test /coordinate with agent-based classification
/coordinate "research authentication patterns and create implementation plan"

# Verify:
# - No timeout occurs
# - Classification completes in <10s
# - WORKFLOW_SCOPE correctly set
# - State machine initializes successfully
# - Research phase receives correct topic count
```

**Validation Criteria**:
- Agent invocation succeeds for various workflow descriptions
- Classification JSON parsed correctly
- sm_init receives all required parameters
- No timeouts occur
- Error messages are clear and actionable
- State machine transitions to correct terminal state

**Files Modified**:
- `.claude/commands/coordinate.md` (lines 164-188, ~60 lines added)

**Dependencies**: Phase 1 (agent), Phase 2 (sm_init refactor)

---

### Phase 4: Update Checkpoint Schema to v2.1 with Classification

**Objective**: Extend checkpoint schema to include classification metadata for resumability.

**Complexity**: Medium

**Tasks**:
- [ ] Update checkpoint save functions in `.claude/lib/workflow-state-machine.sh:698-768`:
  - Add `sm_save_with_classification()` function:
  ```bash
  # sm_save_with_classification - Save checkpoint including classification metadata
  # Args:
  #   $1: checkpoint_file - Path to checkpoint file
  # Returns:
  #   0: Success
  #   1: Error
  sm_save_with_classification() {
    local checkpoint_file="$1"

    # Build classification section from current exports
    local classification_json
    classification_json=$(jq -n \
      --arg workflow_type "$WORKFLOW_SCOPE" \
      --argjson research_complexity "$RESEARCH_COMPLEXITY" \
      --argjson research_topics "$RESEARCH_TOPICS_JSON" \
      --arg classified_at "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
      '{
        workflow_type: $workflow_type,
        research_complexity: ($research_complexity | tonumber),
        research_topics: $research_topics,
        confidence: 0.95,
        reasoning: "Loaded from checkpoint",
        classified_at: $classified_at
      }')

    # Build state machine section (v2.1 schema)
    local state_machine_json
    state_machine_json=$(jq -n \
      --arg current_state "$CURRENT_STATE" \
      --argjson completed_states "$(printf '%s\n' "${COMPLETED_STATES[@]}" | jq -R . | jq -s .)" \
      --arg scope "$WORKFLOW_SCOPE" \
      --arg description "$WORKFLOW_DESCRIPTION" \
      --arg command "$COMMAND_NAME" \
      --argjson classification "$classification_json" \
      '{
        current_state: $current_state,
        completed_states: $completed_states,
        workflow_config: {
          scope: $scope,
          description: $description,
          command: $command
        },
        classification: $classification
      }')

    # Build complete checkpoint (v2.1)
    jq -n \
      --arg schema_version "2.1" \
      --arg checkpoint_id "${CHECKPOINT_ID:-coordinate_$(date +%Y%m%d_%H%M%S)}" \
      --arg workflow_type "$COMMAND_NAME" \
      --argjson state_machine "$state_machine_json" \
      '{
        schema_version: $schema_version,
        checkpoint_id: $checkpoint_id,
        workflow_type: $workflow_type,
        state_machine: $state_machine,
        phase_data: {},
        supervisor_state: {},
        error_state: {
          last_error: null,
          retry_count: 0,
          failed_state: null
        }
      }' > "$checkpoint_file"

    return $?
  }
  ```
- [ ] Update checkpoint load functions in `.claude/lib/workflow-state-machine.sh:478-559`:
  - Add `sm_load_with_classification()` function:
  ```bash
  # sm_load_with_classification - Load checkpoint including classification metadata
  # Args:
  #   $1: checkpoint_file - Path to checkpoint file
  # Returns:
  #   0: Success
  #   1: Error
  sm_load_with_classification() {
    local checkpoint_file="$1"

    # Verify checkpoint file exists
    if [ ! -f "$checkpoint_file" ]; then
      echo "ERROR: Checkpoint file not found: $checkpoint_file" >&2
      return 1
    fi

    # Load v2.1 checkpoint with classification
    CURRENT_STATE=$(jq -r '.state_machine.current_state' "$checkpoint_file")
    WORKFLOW_SCOPE=$(jq -r '.state_machine.classification.workflow_type' "$checkpoint_file")
    RESEARCH_COMPLEXITY=$(jq -r '.state_machine.classification.research_complexity' "$checkpoint_file")
    RESEARCH_TOPICS_JSON=$(jq -c '.state_machine.classification.research_topics' "$checkpoint_file")

    # Export to bash environment
    export CURRENT_STATE
    export WORKFLOW_SCOPE
    export RESEARCH_COMPLEXITY
    export RESEARCH_TOPICS_JSON

    # Set terminal state from classification
    case "$WORKFLOW_SCOPE" in
      research-only) TERMINAL_STATE="$STATE_RESEARCH" ;;
      research-and-plan) TERMINAL_STATE="$STATE_PLAN" ;;
      research-and-revise) TERMINAL_STATE="$STATE_PLAN" ;;
      full-implementation) TERMINAL_STATE="$STATE_COMPLETE" ;;
      debug-only) TERMINAL_STATE="$STATE_DEBUG" ;;
      *)
        echo "ERROR: Invalid workflow_scope in checkpoint: $WORKFLOW_SCOPE" >&2
        return 1
        ;;
    esac

    echo "✓ Checkpoint loaded with classification metadata" >&2
    echo "  Workflow Type: $WORKFLOW_SCOPE" >&2
    echo "  Research Complexity: $RESEARCH_COMPLEXITY" >&2
    echo "  Current State: $CURRENT_STATE" >&2

    return 0
  }
  ```
- [ ] Add early checkpoint save to /coordinate after sm_init (line 188):
  ```bash
  # Save initial checkpoint with classification metadata (enables early resume)
  CHECKPOINT_FILE="${CHECKPOINT_DIR}/initial_checkpoint.json"
  if ! sm_save_with_classification "$CHECKPOINT_FILE"; then
    echo "WARNING: Failed to save initial checkpoint" >&2
    # Continue (non-fatal)
  else
    echo "✓ Initial checkpoint saved: $CHECKPOINT_FILE"
  fi
  ```
- [ ] Update sm_transition() to use atomic checkpoint coordination (`.claude/lib/workflow-state-machine.sh:570-615`):
  ```bash
  sm_transition() {
    local next_state="$1"

    # Phase 1: Validate transition
    if ! validate_transition "$CURRENT_STATE" "$next_state"; then
      return 1
    fi

    # Phase 2: Pre-transition checkpoint (atomic save)
    local pre_checkpoint="${CHECKPOINT_DIR}/pre_transition_${next_state}.json"
    if ! sm_save_with_classification "$pre_checkpoint"; then
      echo "ERROR: Pre-transition checkpoint failed" >&2
      return 1
    fi

    # Phase 3: Update state (in-memory)
    local old_state="$CURRENT_STATE"
    CURRENT_STATE="$next_state"
    COMPLETED_STATES+=("$next_state")

    # Phase 4: Persist to state file
    if ! append_workflow_state "CURRENT_STATE" "$CURRENT_STATE"; then
      # Rollback
      CURRENT_STATE="$old_state"
      unset 'COMPLETED_STATES[-1]'
      echo "ERROR: State file update failed, rolled back" >&2
      return 1
    fi

    # Phase 5: Post-transition checkpoint
    local post_checkpoint="${CHECKPOINT_DIR}/post_transition_${next_state}.json"
    sm_save_with_classification "$post_checkpoint" || true  # Non-fatal

    # Phase 6: Cleanup pre-transition checkpoint
    rm -f "$pre_checkpoint"

    echo "✓ State transition: $old_state → $CURRENT_STATE (atomic)" >&2
    return 0
  }
  ```

**Testing**:
```bash
# Test checkpoint save with classification
source .claude/lib/workflow-state-machine.sh
WORKFLOW_SCOPE="research-and-plan"
RESEARCH_COMPLEXITY=2
RESEARCH_TOPICS_JSON='[{"short_name":"topic1","detailed_description":"desc","filename_slug":"topic1","research_focus":"focus"}]'
export WORKFLOW_SCOPE RESEARCH_COMPLEXITY RESEARCH_TOPICS_JSON

CURRENT_STATE="research"
COMPLETED_STATES=("initialize")
CHECKPOINT_FILE="/tmp/test_checkpoint_v2.1.json"

sm_save_with_classification "$CHECKPOINT_FILE"
cat "$CHECKPOINT_FILE" | jq .

# Verify schema_version is "2.1"
# Verify classification section exists
# Verify all classification fields present

# Test checkpoint load
sm_load_with_classification "$CHECKPOINT_FILE"
echo "WORKFLOW_SCOPE=$WORKFLOW_SCOPE"
echo "RESEARCH_COMPLEXITY=$RESEARCH_COMPLEXITY"
# Expected: Values restored correctly
```

**Validation Criteria**:
- Checkpoint saves with schema_version: "2.1"
- Classification section includes all required fields
- Checkpoint load restores classification metadata
- State transitions create pre/post checkpoints
- Rollback works on state file failure
- Early checkpoint created after sm_init

**Files Modified**:
- `.claude/lib/workflow-state-machine.sh` (lines 478-559, 570-615, 698-768, ~150 lines added/changed)
- `.claude/commands/coordinate.md` (line 188, ~10 lines added)

**Dependencies**: Phase 2 (sm_init exports classification)

---

### Phase 5: Remove File-Based Signaling Code (Clean-Break)

**Objective**: Delete obsolete file-based classification infrastructure.

**Complexity**: Low

**Tasks**:
- [ ] Delete `invoke_llm_classifier()` function from `.claude/lib/workflow-llm-classifier.sh:287-359`
- [ ] Delete `cleanup_workflow_classification_files()` function (lines 650-677)
- [ ] Delete all cleanup invocations from /coordinate (lines 428, 999, 1453, 1709, 1844, 2063)
- [ ] Remove classification temp file logic:
  - Request file creation
  - Response file polling
  - Stderr marker emission
- [ ] Update function docstrings to remove references to file-based pattern
- [ ] Remove test mode file-based fixtures (lines 119-164):
  - Keep test mode concept, but update to return JSON directly
  - No file writes needed
- [ ] Update error handling functions to remove file-based error types:
  - Remove `ERROR_TYPE_LLM_TIMEOUT` (no longer applicable)
  - Keep network, parse, validation errors
- [ ] Simplify library to keep only:
  - `build_llm_classifier_input()` - JSON input construction (reusable)
  - `parse_llm_classifier_response()` - Response validation (reusable)
  - Error handling constants and functions

**Testing**:
```bash
# Verify file-based code removed
grep -n "llm_request_\|llm_response_\|LLM_CLASSIFICATION_REQUEST" .claude/lib/workflow-llm-classifier.sh
# Expected: No matches

# Verify cleanup removed from commands
grep -n "cleanup_workflow_classification_files" .claude/commands/coordinate.md
# Expected: No matches

# Verify no temp files created during workflow
/coordinate "test workflow"
ls ~/.claude/tmp/llm_*
# Expected: No such files
```

**Validation Criteria**:
- No file-based signaling code remains
- No cleanup functions exist
- No temp files created during workflows
- Library still provides reusable utilities
- All tests pass after cleanup

**Files Modified**:
- `.claude/lib/workflow-llm-classifier.sh` (delete ~200 lines)
- `.claude/commands/coordinate.md` (delete 6 cleanup invocations)

**Dependencies**: Phase 3 (commands use agent)

---

### Phase 6: Update /orchestrate and /supervise Commands

**Objective**: Apply same agent invocation pattern to other orchestration commands.

**Complexity**: Low (repeat Phase 3 pattern)

**Tasks**:
- [ ] Update `/orchestrate` command (`.claude/commands/orchestrate.md`):
  - Add Phase 0: Workflow Classification (same pattern as /coordinate)
  - Update sm_init call with classification parameters
  - Remove old error handling for classification timeout
  - Add early checkpoint save
- [ ] Update `/supervise` command (`.claude/commands/supervise.md`):
  - Add Phase 0: Workflow Classification
  - Update sm_init call with classification parameters
  - Remove old error handling
  - Add early checkpoint save
- [ ] Ensure all three commands use identical agent invocation pattern:
  - Same Task tool structure
  - Same parsing logic
  - Same validation checks
  - Same error messages

**Testing**:
```bash
# Test /orchestrate
/orchestrate "research database patterns and create implementation plan"
# Verify no timeout, correct classification

# Test /supervise
/supervise "research API design patterns to create plan"
# Verify no timeout, correct classification

# Test all workflow types across all commands
for cmd in coordinate orchestrate supervise; do
  /$cmd "research only: analyze authentication patterns"
  # Expected: workflow_type=research-only
done
```

**Validation Criteria**:
- All three commands classify successfully
- No timeouts occur
- Classification results consistent across commands
- Error messages clear and actionable
- Early checkpoints created

**Files Modified**:
- `.claude/commands/orchestrate.md` (~60 lines added/changed)
- `.claude/commands/supervise.md` (~60 lines added/changed)

**Dependencies**: Phase 3 (pattern established in /coordinate)

---

## Testing Strategy

### Unit Testing

**Agent Testing**:
```bash
# Test classification agent with edge cases
# (Manual testing via Claude Code Task tool)

# Test case 1: Ambiguous description
"research the research-and-revise workflow"
# Expected: workflow_type=research-and-plan (intent: learn about workflow type)

# Test case 2: Negation
"don't revise the plan, create a new implementation plan"
# Expected: workflow_type=research-and-plan

# Test case 3: Quoted keywords
"research the 'implement' command to understand how it works"
# Expected: workflow_type=research-only

# Test case 4: Complex workflow
"research authentication, plan implementation, and implement the solution"
# Expected: workflow_type=full-implementation
```

**State Machine Testing**:
```bash
# Test sm_init with valid parameters
source .claude/lib/workflow-state-machine.sh
sm_init "test" "coordinate" "research-and-plan" 2 '[...]'
# Expected: Success, exports set

# Test sm_init fail-fast validation
sm_init "test" "coordinate" "" 2 '[]'
# Expected: ERROR: sm_init requires classification parameters

sm_init "test" "coordinate" "invalid-type" 2 '[]'
# Expected: ERROR: Invalid workflow_type

# Test checkpoint save/load
sm_save_with_classification "/tmp/checkpoint.json"
sm_load_with_classification "/tmp/checkpoint.json"
# Expected: Classification metadata preserved
```

### Integration Testing

**End-to-End Workflow Testing**:
```bash
# Test complete /coordinate workflow
/coordinate "research authentication patterns and create implementation plan"

# Verify checkpoints:
CHECKPOINT_DIR="$HOME/.claude/checkpoints/coordinate_*"
cat "$CHECKPOINT_DIR/initial_checkpoint.json" | jq .state_machine.classification
# Expected: Classification section with all fields

# Verify state transitions:
cat "$CHECKPOINT_DIR/post_transition_research.json" | jq .state_machine.current_state
# Expected: "research"

# Test workflow resume:
# 1. Start workflow
/coordinate "test workflow"
# 2. Kill during research phase (Ctrl+C)
# 3. Resume
/coordinate --resume
# Expected: Loads classification from checkpoint, continues from saved state
```

**Regression Testing**:
```bash
# Run existing orchestration workflows
# Verify no behavior changes except timeout elimination

# Test all workflow types
/coordinate "research only: analyze patterns"  # research-only
/coordinate "research and plan implementation"  # research-and-plan
/coordinate "implement authentication system"   # full-implementation
/coordinate "debug login failures"              # debug-only

# Verify terminal states match workflow types
```

### Performance Testing

**Classification Speed**:
```bash
# Measure classification time
time /coordinate "research authentication patterns"
# Expected: Total <15s (classification ~3-5s)

# Compare to old timeout (10s wasted)
# Expected: ~10s faster due to timeout elimination
```

**Checkpoint Performance**:
```bash
# Measure checkpoint save time
time sm_save_with_classification "/tmp/checkpoint.json"
# Expected: <100ms (atomic jq operations)
```

## Documentation Requirements

### New Documentation

1. **Agent Behavioral File** (Phase 1):
   - File: `.claude/agents/workflow-classifier.md`
   - Content: Classification rules, examples, schema
   - ~300 lines

2. **Migration Summary** (Phase 6 completion):
   - Add to OVERVIEW.md summary section
   - Document clean-break approach
   - Link to this implementation plan

### Updated Documentation

1. **Command Guides**:
   - `.claude/docs/guides/coordinate-command-guide.md`
   - Add Phase 0: Workflow Classification section
   - Update architecture diagrams
   - Document agent invocation pattern

2. **State Machine Documentation**:
   - `.claude/docs/architecture/state-based-orchestration-overview.md`
   - Update initialization flow
   - Document classification happens before sm_init
   - Update checkpoint schema section (v2.1)

3. **Library API Reference**:
   - `.claude/docs/reference/library-api.md`
   - Update sm_init signature documentation
   - Remove file-based classification references
   - Document sm_save_with_classification, sm_load_with_classification

4. **LLM Classification Pattern**:
   - `.claude/docs/concepts/patterns/llm-classification-pattern.md`
   - Replace file-based approach with agent-based
   - Update architecture diagrams
   - Add troubleshooting section

## Dependencies

**External**:
- Claude Code Task tool (available)
- jq (already used in codebase)
- Haiku model (available via subagent_type: general-purpose)

**Internal**:
- State persistence library (`.claude/lib/state-persistence.sh`)
- Checkpoint utilities (`.claude/lib/checkpoint-utils.sh`)
- Workflow state machine (`.claude/lib/workflow-state-machine.sh`)

**Phase Dependencies**:
```
Phase 1 (Agent) → Phase 3 (Commands)
Phase 2 (sm_init) → Phase 3 (Commands)
Phase 2 (sm_init) → Phase 4 (Checkpoints)
Phase 3 (Commands) → Phase 5 (Cleanup)
Phase 3 (Commands) → Phase 6 (Other Commands)
```

## Risks and Mitigation

### Risk 1: Agent Classification Accuracy

**Probability**: Low
**Impact**: Medium (incorrect workflow routing)

**Mitigation**:
- Comprehensive examples in agent behavioral file
- Manual validation of edge cases during Phase 1
- Confidence threshold enforcement (>0.7)
- User can override via WORKFLOW_CLASSIFICATION_MODE=regex-only (fallback)

### Risk 2: Breaking Existing Workflows

**Probability**: Low
**Impact**: High (all orchestration commands affected)

**Mitigation**:
- Comprehensive testing in Phase 6
- Regression test suite covering all workflow types
- Clear error messages for classification failures
- Fail-fast approach prevents silent failures

### Risk 3: Checkpoint Migration

**Probability**: Medium
**Impact**: Low (old checkpoints won't load)

**Mitigation**:
- v2.0 checkpoints lack classification metadata (already incomplete)
- Resume requires re-classification anyway (acceptable)
- Clear error message if v2.0 checkpoint loaded
- No automatic migration (clean-break approach)

## Notes

### Clean-Break Rationale

This implementation follows clean-break philosophy:
- **No backward compatibility**: Old sm_init signature removed entirely
- **No dual-path logic**: Single implementation, no if/else for classification source
- **No deprecated code**: File-based signaling deleted immediately
- **No migration period**: All commands updated simultaneously

**Justification**:
- File-based signaling never worked (0% success rate)
- No production code depends on broken pattern
- Cleaner architecture without compatibility shims
- Faster implementation (no dual-path testing)
- Better maintainability (no cruft)

### State Machine Integration

Classification now occurs BEFORE state machine initialization:
- Commands own classification (via Task tool)
- State machine receives pre-computed results
- Clean separation: commands orchestrate, state machine manages state
- Aligns with architectural principle: "libraries provide utilities, not orchestration"

### Checkpoint Resumability

Classification metadata in checkpoints enables complete resume:
- Terminal state calculated from workflow_type
- Research topics allocated from research_complexity
- Dynamic path allocation uses correct values
- No re-classification needed (faster resume)

### Future Enhancements

**Not in this plan** (documented for future consideration):
- Adaptive classification based on codebase analysis
- Classification confidence-based workflow adjustments
- Multi-model classification for consensus
- Classification result caching across similar descriptions
