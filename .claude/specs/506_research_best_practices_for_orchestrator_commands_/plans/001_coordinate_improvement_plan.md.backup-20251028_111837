# /coordinate Command Improvement Plan

## Metadata
- **Date**: 2025-10-28
- **Feature**: Improve /coordinate command for efficiency and economy
- **Scope**: Apply orchestrator best practices while maintaining wave-based parallel execution
- **Estimated Phases**: 8
- **Estimated Hours**: 12-16 hours
- **Structure Level**: 0
- **Complexity Score**: 48.0
- **Standards File**: /home/benjamin/.config/CLAUDE.md
- **Research Reports**:
  - /home/benjamin/.config/.claude/specs/506_research_best_practices_for_orchestrator_commands_/reports/001_orchestrator_best_practices.md
  - /home/benjamin/.config/.claude/specs/506_research_best_practices_for_orchestrator_commands_/reports/002_coordinate_command_analysis.md

## Overview

The /coordinate command (2,148 lines) provides wave-based parallel execution achieving 40-60% time savings over sequential workflows. This plan implements targeted improvements based on orchestrator best practices research while preserving the core wave-based functionality that differentiates /coordinate from /supervise.

The improvements focus on:
1. Enhancing agent invocation patterns to eliminate any remaining anti-patterns
2. Optimizing context management for <30% usage target
3. Strengthening verification checkpoints for 100% reliability
4. Improving error handling with enhanced diagnostics
5. Adding performance instrumentation and validation

## Research Summary

Key findings from research reports:

**From Orchestrator Best Practices (Report 001)**:
- Imperative agent invocation pattern achieves >90% delegation rate (vs 0% with documentation-only YAML)
- Three-layer verification defense achieves 100% file creation reliability
- Metadata extraction provides 95% context reduction (5,000 → 250 tokens)
- Fail-fast error handling with 5-component messages enables rapid debugging
- Unified location detection provides 85% token reduction and 25x speedup

**From /coordinate Analysis (Report 002)**:
- 2,148 lines total, 18% larger than /supervise due to wave-based infrastructure
- Wave-based execution adds ~330 lines but provides 40-60% time savings
- Phases 4-6 (Testing, Debug, Documentation) identical to /supervise - consolidation opportunity
- Dependency-analyzer.sh library (639 lines) implements Kahn's algorithm for wave calculation
- All verification patterns follow fail-fast philosophy with comprehensive diagnostics

**Recommended Approach**:
Apply best practices from spec 497 unified improvements while preserving wave-based execution differentiation. Focus on context management optimization, agent invocation pattern validation, and performance instrumentation.

## Success Criteria

- [ ] All agent invocations use imperative pattern (no documentation-only YAML blocks)
- [ ] File creation reliability: 100% (verified via test suite)
- [ ] Context usage: <30% throughout 7-phase workflow
- [ ] Wave-based execution preserved (40-60% time savings maintained)
- [ ] Enhanced error messages with 5-component structure
- [ ] Performance instrumentation for context and wave execution metrics
- [ ] Validation tests for anti-pattern detection
- [ ] Documentation updated with decision criteria and best practices

## Technical Design

### Architecture Principles

1. **Preserve Wave-Based Differentiation**: Maintain Phase 3 wave-based infrastructure as core value proposition
2. **Apply Unified Standards**: Implement patterns from spec 497 across all orchestration commands
3. **Optimize Context Management**: Aggressive pruning and metadata extraction for <30% target
4. **Fail-Fast Philosophy**: Enhanced error messages, no silent degradation
5. **Performance Visibility**: Instrumentation for context usage and wave execution metrics

### Component Interactions

```
Phase 0 (Location)
  ↓ [Unified location detection library]
Phase 1 (Research)
  ↓ [Parallel agents with metadata extraction]
Phase 2 (Planning)
  ↓ [Plan-architect with research synthesis]
Phase 3 (Wave Implementation) ← DIFFERENTIATOR
  ↓ [Dependency analysis → Wave calculation → Parallel execution]
Phase 4 (Testing)
  ↓ [Test-specialist with results verification]
Phase 5 (Debug - conditional)
  ↓ [Debug-analyst with iterative fixes]
Phase 6 (Documentation - conditional)
  ↓ [Doc-writer with summary creation]

Performance Instrumentation Layer:
  - Context size tracking at phase boundaries
  - Wave execution metrics (parallel phases, time saved)
  - File creation verification logging
  - Error classification and recovery tracking
```

### Key Design Decisions

1. **Maintain Phase 3 Uniqueness**: Wave-based execution stays as /coordinate's differentiation
2. **Consolidate Phases 4-6**: Extract to shared library for consistency with /supervise
3. **Enhanced Progress Markers**: Wave-specific visibility (Wave 1/4 starting, N phases parallel)
4. **Performance Instrumentation**: Context usage and wave metrics logged for validation
5. **Anti-Pattern Validation**: Add to test suite for regression prevention

## Implementation Phases

### Phase 0: Validation and Baseline Measurement
dependencies: []

**Objective**: Validate current implementation against best practices and establish performance baseline

**Complexity**: Low

**Tasks**:
- [ ] Run `.claude/lib/validate-agent-invocation-pattern.sh` on coordinate.md
- [ ] Document any detected anti-patterns or warnings
- [ ] Measure baseline context usage across sample 7-phase workflow
- [ ] Measure baseline wave execution performance (3 test cases)
- [ ] Document current file creation reliability rate
- [ ] Review all agent invocation blocks for imperative pattern compliance
- [ ] Identify any code-fenced YAML blocks or undermining disclaimers

**Testing**:
```bash
# Anti-pattern detection
.claude/lib/validate-agent-invocation-pattern.sh .claude/commands/coordinate.md

# Baseline measurements
.claude/tests/test_orchestration_commands.sh --command coordinate --measure-baseline
```

**Expected Duration**: 1-2 hours

**Phase 0 Completion Requirements**:
- [ ] All phase tasks marked [x]
- [ ] Validation script executed with results documented
- [ ] Baseline metrics captured for comparison
- [ ] Git commit created: `feat(506): complete Phase 0 - Validation and Baseline`

### Phase 1: Agent Invocation Pattern Enhancement
dependencies: []

**Objective**: Ensure all agent invocations use imperative pattern with no anti-patterns

**Complexity**: Medium

**Tasks**:
- [ ] Review Phase 1 (Research) agent invocations (lines 831-865)
- [ ] Verify imperative directives present ("**EXECUTE NOW**: USE the Task tool")
- [ ] Check for any code-fenced YAML blocks around Task invocations
- [ ] Review Phase 2 (Planning) agent invocation (lines 1120-1143)
- [ ] Review Phase 3 (Implementation) agent invocations (lines 1373-1400)
- [ ] Review Phase 4-6 agent invocations for consistency
- [ ] Add imperative reinforcement if any passive language detected
- [ ] Remove any documentation-only code fences
- [ ] Validate no undermining disclaimers follow imperative directives
- [ ] Test agent delegation rate (target: >90%)

**Testing**:
```bash
# Delegation rate testing
.claude/tests/test_orchestration_commands.sh --command coordinate --test-delegation

# Expected: >90% delegation rate, 100% file creation in correct locations
```

**Expected Duration**: 2-3 hours

<!-- PROGRESS CHECKPOINT -->
After completing the above tasks:
- [ ] Update this plan file: Mark completed tasks with [x]
- [ ] Verify changes with git diff
<!-- END PROGRESS CHECKPOINT -->

**Phase 1 Completion Requirements**:
- [ ] All phase tasks marked [x]
- [ ] Tests passing (delegation rate >90%)
- [ ] Git commit created: `feat(506): complete Phase 1 - Agent Invocation Enhancement`
- [ ] Update this plan file with phase completion status

### Phase 2: Context Management Optimization
dependencies: [1]

**Objective**: Implement aggressive context pruning and metadata extraction for <30% target

**Complexity**: Medium

**Tasks**:
- [ ] Review current context pruning strategy (lines 1501-1515, phase-specific pruning)
- [ ] Enhance metadata extraction after Phase 1 (research reports)
- [ ] Implement layered context architecture (permanent, phase-scoped, metadata, transient)
- [ ] Add context size measurement at each phase boundary
- [ ] Implement aggressive pruning after Phase 3 (wave metadata retention only)
- [ ] Add forward message pattern validation (no re-summarization)
- [ ] Optimize checkpoint data structure (minimal metadata storage)
- [ ] Add context usage logging via unified-logger.sh
- [ ] Test context usage across 7-phase workflow
- [ ] Validate <30% target achieved

**Testing**:
```bash
# Context usage measurement
.claude/tests/test_orchestration_commands.sh --command coordinate --measure-context

# Expected: <30% usage throughout workflow
```

**Expected Duration**: 2-3 hours

<!-- PROGRESS CHECKPOINT -->
After completing the above tasks:
- [ ] Update this plan file: Mark completed tasks with [x]
- [ ] Verify changes with git diff
<!-- END PROGRESS CHECKPOINT -->

**Phase 2 Completion Requirements**:
- [ ] All phase tasks marked [x]
- [ ] Tests passing (context usage <30%)
- [ ] Git commit created: `feat(506): complete Phase 2 - Context Management Optimization`
- [ ] Update this plan file with phase completion status

### Phase 3: Verification Checkpoint Enhancement
dependencies: [1]

**Objective**: Strengthen verification checkpoints to ensure 100% file creation reliability

**Complexity**: Medium

**Tasks**:
- [ ] Review all verification checkpoints (Phases 1, 2, 3, 4, 5, 6)
- [ ] Enhance Phase 1 research verification (lines 867-985)
- [ ] Enhance Phase 2 plan verification (lines 1145-1223)
- [ ] Enhance Phase 3 implementation verification (lines 1402-1515)
- [ ] Add file size checks (minimum thresholds for quality validation)
- [ ] Add structure validation (markdown headers, required sections)
- [ ] Implement single-retry for transient failures only
- [ ] Add verification logging for audit trail
- [ ] Test file creation reliability (10 workflow executions)
- [ ] Validate 100% success rate achieved

**Testing**:
```bash
# File creation reliability testing
for i in {1..10}; do
  .claude/tests/test_orchestration_commands.sh --command coordinate --test-reliability
done

# Expected: 10/10 success rate
```

**Expected Duration**: 2 hours

<!-- PROGRESS CHECKPOINT -->
After completing the above tasks:
- [ ] Update this plan file: Mark completed tasks with [x]
- [ ] Verify changes with git diff
<!-- END PROGRESS CHECKPOINT -->

**Phase 3 Completion Requirements**:
- [ ] All phase tasks marked [x]
- [ ] Tests passing (100% file creation reliability)
- [ ] Git commit created: `feat(506): complete Phase 3 - Verification Enhancement`
- [ ] Update this plan file with phase completion status

### Phase 4: Error Handling Enhancement
dependencies: [3]

**Objective**: Implement 5-component error message structure for rapid debugging

**Complexity**: Medium

**Tasks**:
- [ ] Review current error messages across all phases
- [ ] Enhance Phase 1 research failure messages (lines 906-945)
- [ ] Enhance Phase 2 planning failure messages (lines 1183-1223)
- [ ] Enhance Phase 3 implementation failure messages (lines 1437-1451)
- [ ] Implement 5-component structure (what failed, expected, diagnostic, context, action)
- [ ] Add specific diagnostic commands to each error message
- [ ] Enhance library sourcing error messages (lines 362-388)
- [ ] Add error classification using error-handling.sh utilities
- [ ] Test error message clarity with sample failures
- [ ] Validate fail-fast behavior (no silent degradation)

**Testing**:
```bash
# Error handling testing
.claude/tests/test_orchestration_commands.sh --command coordinate --test-error-handling

# Manually trigger errors and verify message quality
```

**Expected Duration**: 2 hours

<!-- PROGRESS CHECKPOINT -->
After completing the above tasks:
- [ ] Update this plan file: Mark completed tasks with [x]
- [ ] Verify changes with git diff
<!-- END PROGRESS CHECKPOINT -->

**Phase 4 Completion Requirements**:
- [ ] All phase tasks marked [x]
- [ ] Tests passing (error messages validated)
- [ ] Git commit created: `feat(506): complete Phase 4 - Error Handling Enhancement`
- [ ] Update this plan file with phase completion status

### Phase 5: Wave Execution Enhancement and Validation
dependencies: [2]

**Objective**: Enhance wave-based execution visibility and add comprehensive validation

**Complexity**: High

**Tasks**:
- [ ] Review dependency-analyzer.sh library for optimization opportunities
- [ ] Add enhanced progress markers for wave execution (Wave 1/4 starting, N phases parallel)
- [ ] Implement wave execution metrics logging (parallel_phases, time_saved, duration)
- [ ] Add wave checkpoint validation after each wave completion
- [ ] Create comprehensive wave execution test suite (.claude/tests/test_wave_execution.sh)
- [ ] Test circular dependency detection
- [ ] Test wave calculation for various dependency patterns (10, 20, 50 phase plans)
- [ ] Benchmark dependency parsing performance
- [ ] Add wave execution examples to documentation
- [ ] Validate 40-60% time savings maintained

**Testing**:
```bash
# Wave execution comprehensive testing
.claude/tests/test_wave_execution.sh

# Performance benchmarking
.claude/tests/benchmark_wave_execution.sh --phases 10,20,50

# Expected: >80% code coverage, validated time savings
```

**Expected Duration**: 3-4 hours

<!-- PROGRESS CHECKPOINT -->
After completing the above tasks:
- [ ] Update this plan file: Mark completed tasks with [x]
- [ ] Verify changes with git diff
<!-- END PROGRESS CHECKPOINT -->

**Phase 5 Completion Requirements**:
- [ ] All phase tasks marked [x]
- [ ] Tests passing (wave execution validated, >80% coverage)
- [ ] Git commit created: `feat(506): complete Phase 5 - Wave Execution Enhancement`
- [ ] Update this plan file with phase completion status

### Phase 6: Performance Instrumentation
dependencies: [2, 5]

**Objective**: Add comprehensive performance instrumentation for validation and monitoring

**Complexity**: Low

**Tasks**:
- [ ] Implement context size tracking at each phase boundary
- [ ] Add cumulative context usage reporting at workflow completion
- [ ] Implement wave execution metrics tracking (time saved, parallel phases)
- [ ] Add file creation reliability tracking (success rate per phase)
- [ ] Add error classification tracking (transient vs permanent)
- [ ] Log performance metrics via unified-logger.sh
- [ ] Create performance dashboard view (optional, in workflow summary)
- [ ] Test instrumentation overhead (<5% target)
- [ ] Validate metrics accuracy across sample workflows
- [ ] Document metrics collection and interpretation

**Testing**:
```bash
# Performance instrumentation testing
.claude/tests/test_orchestration_commands.sh --command coordinate --measure-all

# Verify instrumentation overhead <5%
```

**Expected Duration**: 2 hours

<!-- PROGRESS CHECKPOINT -->
After completing the above tasks:
- [ ] Update this plan file: Mark completed tasks with [x]
- [ ] Verify changes with git diff
<!-- END PROGRESS CHECKPOINT -->

**Phase 6 Completion Requirements**:
- [ ] All phase tasks marked [x]
- [ ] Tests passing (instrumentation validated)
- [ ] Git commit created: `feat(506): complete Phase 6 - Performance Instrumentation`
- [ ] Update this plan file with phase completion status

### Phase 7: Documentation and Decision Criteria
dependencies: [6]

**Objective**: Update documentation with best practices, decision criteria, and usage guidance

**Complexity**: Low

**Tasks**:
- [ ] Add decision criteria section to coordinate.md (when to use vs /supervise vs /orchestrate)
- [ ] Document wave-based execution in detail with examples
- [ ] Add best practices section referencing research findings
- [ ] Document performance characteristics and targets
- [ ] Update CLAUDE.md section on orchestration commands
- [ ] Add troubleshooting guide for wave execution issues
- [ ] Document instrumentation metrics and interpretation
- [ ] Create usage examples for different workflow types
- [ ] Add anti-pattern warnings and detection guidance
- [ ] Review and update all inline comments for clarity

**Testing**:
```bash
# Documentation validation
grep -c "when to use" .claude/commands/coordinate.md
grep -c "wave-based execution" .claude/commands/coordinate.md

# Expected: Decision criteria and wave execution sections present
```

**Expected Duration**: 2 hours

<!-- PROGRESS CHECKPOINT -->
After completing the above tasks:
- [ ] Update this plan file: Mark completed tasks with [x]
- [ ] Verify changes with git diff
<!-- END PROGRESS CHECKPOINT -->

**Phase 7 Completion Requirements**:
- [ ] All phase tasks marked [x]
- [ ] Documentation reviewed and validated
- [ ] Git commit created: `feat(506): complete Phase 7 - Documentation Enhancement`
- [ ] Update this plan file with phase completion status

## Testing Strategy

### Unit Testing
- Anti-pattern detection via validate-agent-invocation-pattern.sh
- Agent delegation rate testing (target: >90%)
- File creation reliability testing (target: 100%)
- Context usage measurement (target: <30%)
- Wave execution validation (circular dependency detection, wave calculation correctness)

### Integration Testing
- End-to-end workflow execution (research-only, research-and-plan, full-implementation, debug-only)
- Checkpoint resume capability testing
- Error handling and recovery testing
- Performance instrumentation validation

### Performance Testing
- Dependency parsing benchmarks (10, 20, 50 phase plans)
- Context usage profiling across 7-phase workflow
- Wave execution time savings measurement (target: 40-60%)
- Instrumentation overhead measurement (target: <5%)

### Regression Testing
- Compare baseline metrics to post-improvement metrics
- Validate no functionality degradation
- Verify wave-based execution preserved
- Confirm fail-fast behavior maintained

## Documentation Requirements

### Command File Updates
- Add decision criteria section (when to use /coordinate)
- Enhance wave-based execution documentation with examples
- Add performance characteristics and targets
- Document instrumentation metrics and interpretation

### CLAUDE.md Updates
- Update orchestration commands section with decision matrix
- Document performance expectations for each command
- Add troubleshooting guidance for wave execution

### Test Documentation
- Document test_wave_execution.sh test suite
- Add benchmark_wave_execution.sh usage guide
- Document expected test coverage targets

### Implementation Summary
- Create summary document linking plan, research, and implementation
- Document baseline vs post-improvement metrics
- Record lessons learned and future optimization opportunities

## Dependencies

### Required Libraries
- `.claude/lib/validate-agent-invocation-pattern.sh` - Anti-pattern detection
- `.claude/lib/metadata-extraction.sh` - Context reduction utilities
- `.claude/lib/context-pruning.sh` - Context optimization
- `.claude/lib/unified-logger.sh` - Performance logging
- `.claude/lib/error-handling.sh` - Error classification and recovery
- `.claude/lib/dependency-analyzer.sh` - Wave calculation (existing)
- `.claude/lib/checkpoint-utils.sh` - Resume capability (existing)

### Test Infrastructure
- `.claude/tests/test_orchestration_commands.sh` - Orchestration testing framework
- `.claude/tests/test_wave_execution.sh` - Wave execution test suite (to be created)
- `.claude/tests/benchmark_wave_execution.sh` - Performance benchmarking (to be created)

### Documentation Standards
- Follow Command Architecture Standards (reference: .claude/docs/reference/command_architecture_standards.md)
- Use imperative language guide (.claude/docs/guides/imperative-language-guide.md)
- Follow behavioral injection pattern (.claude/docs/concepts/patterns/behavioral-injection.md)

## Risk Management

### Technical Risks
1. **Risk**: Context optimization may impact wave execution visibility
   - **Mitigation**: Preserve wave metadata until Phase 3 completion, test visibility
   - **Fallback**: Adjust pruning policy to retain more wave details if needed

2. **Risk**: Enhanced verification may add unacceptable overhead
   - **Mitigation**: Benchmark verification time, optimize checks
   - **Fallback**: Simplify checks while maintaining 100% reliability

3. **Risk**: Wave execution tests may be complex to implement
   - **Mitigation**: Start with simple test cases, expand incrementally
   - **Fallback**: Focus on integration tests if unit tests prove difficult

### Process Risks
1. **Risk**: Improvements may introduce regressions in existing functionality
   - **Mitigation**: Comprehensive testing before and after each phase
   - **Fallback**: Git revert to previous working state

2. **Risk**: Documentation updates may become outdated quickly
   - **Mitigation**: Update documentation inline with code changes
   - **Fallback**: Mark documentation sections as "provisional" until stabilized

## Timeline Estimates

- **Phase 0**: 1-2 hours (validation and baseline)
- **Phase 1**: 2-3 hours (agent invocation enhancement)
- **Phase 2**: 2-3 hours (context management)
- **Phase 3**: 2 hours (verification enhancement)
- **Phase 4**: 2 hours (error handling)
- **Phase 5**: 3-4 hours (wave execution enhancement)
- **Phase 6**: 2 hours (performance instrumentation)
- **Phase 7**: 2 hours (documentation)

**Total Estimated Time**: 12-16 hours

**Parallel Execution Opportunities**:
- Phases 1, 2, 3 can be implemented in Wave 1 (no dependencies)
- Phase 4 can start after Phase 3 completes
- Phases 5 and 6 can run in parallel after Phase 2 completes
- Phase 7 must wait for all other phases

**Wave-Based Timeline**:
- Wave 1: Phases 1, 2, 3 (max 3 hours)
- Wave 2: Phase 4 (2 hours)
- Wave 3: Phases 5, 6 (max 4 hours)
- Wave 4: Phase 7 (2 hours)

**Wave-Based Total**: 11 hours (vs 16 hours sequential, ~30% time savings)

## Approval and Sign-Off

This plan is ready for implementation via `/implement` command.

**Recommended Approach**:
```bash
/implement /home/benjamin/.config/.claude/specs/506_research_best_practices_for_orchestrator_commands_/plans/001_coordinate_improvement_plan.md
```

**Expected Outcome**:
- /coordinate command improved with best practices
- 100% file creation reliability verified
- <30% context usage achieved
- Wave-based execution preserved (40-60% time savings)
- Comprehensive test coverage (>80%)
- Enhanced documentation with decision criteria
