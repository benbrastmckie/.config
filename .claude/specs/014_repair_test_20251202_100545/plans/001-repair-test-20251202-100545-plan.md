# /test Command Error Repair Implementation Plan

## Metadata
- **Date**: 2025-12-02
- **Feature**: Fix /test command errors (ERR trap false positives and state machine complexity validation)
- **Status**: [COMPLETE]
- **Estimated Hours**: 4-6 hours
- **Standards File**: /home/benjamin/.config/CLAUDE.md
- **Research Reports**:
  - [Error Analysis Report](../reports/001-test-errors-repair.md)
- **Complexity Score**: 52.0
- **Structure Level**: 0
- **Error Log Query**: --command /test
- **Errors Addressed**: 4 errors (3 ERR trap false positives, 1 state machine validation error)

## Overview

This plan addresses two distinct error patterns affecting the /test command:

1. **ERR Trap False Positives** (75% of errors): The ERR trap in error-handling.sh logs intentional test framework errors as real errors, creating noise in the error log. Test scripts that deliberately trigger failures for validation purposes are captured by the bash error trap.

2. **State Machine Complexity Validation** (25% of errors): The workflow state machine's `sm_init` function hard-fails when receiving complexity scores outside the 1-4 range (e.g., legacy score of 78.5), causing cascading initialization failures and blocking test execution.

Both issues require targeted fixes to improve error detection accuracy and workflow robustness.

## Research Summary

Analysis of 4 errors from `/test` command over 11 days revealed:

- **Pattern 1** (3 errors): ERR trap capturing test framework failures from scripts in `/tmp/test_*.sh` that intentionally trigger errors (e.g., `false` command, failing conditionals). These are expected test behaviors, not real errors.

- **Pattern 2** (1 error): State machine complexity validation rejecting value "5" from plan with legacy complexity score 78.5, causing STATE_FILE initialization failure and cascading "STATE_FILE not set" errors.

Research identified root causes:
- ERR trap lacks test context awareness (workflow IDs, script paths, environment variables)
- State machine has rigid 1-4 validation without normalization or graceful degradation
- No fallback initialization when validation fails

## Success Criteria

- [x] ERR trap skips logging for test framework contexts (test workflow IDs, /tmp/test_*.sh paths)
- [x] State machine normalizes complexity scores outside 1-4 range to valid values
- [x] State machine initializes STATE_FILE even when complexity validation fails
- [x] Error log contains no false positive errors from test frameworks
- [x] /test command executes successfully with out-of-range complexity values
- [x] All unit tests pass for error handling and state machine changes
- [x] Integration tests verify end-to-end /test command workflow
- [x] Error log entries for this plan marked RESOLVED

## Technical Design

### Architecture Changes

**1. Test Context Detection in error-handling.sh**

Add context-aware error logging that detects test execution environments and suppresses logging for intentional test failures:

```bash
# New function: is_test_context
# Returns 0 if current context is a test execution, 1 otherwise
is_test_context() {
  # Check 1: Workflow ID pattern (test_*)
  if [[ "${WORKFLOW_ID:-}" =~ ^test_ ]]; then
    return 0
  fi

  # Check 2: Calling script in /tmp/test_*.sh
  local caller_script="${BASH_SOURCE[2]:-}"
  if [[ "$caller_script" =~ /tmp/test_.*\.sh$ ]]; then
    return 0
  fi

  # Check 3: Environment variable override
  if [ "${SUPPRESS_ERR_LOGGING:-0}" = "1" ]; then
    return 0
  fi

  return 1
}
```

Integration points in `_log_bash_exit` and `_log_bash_error`:
- Call `is_test_context` before logging
- Skip logging if test context detected
- Preserve logging for non-test contexts

**2. Complexity Normalization in workflow-state-machine.sh**

Add flexible complexity handling that normalizes out-of-range values and provides graceful degradation:

```bash
# New function: normalize_complexity
# Maps any numeric input to 1-4 range, returns default 2 for invalid
normalize_complexity() {
  local input="$1"

  # Validate numeric input
  if ! [[ "$input" =~ ^[0-9]+\.?[0-9]*$ ]]; then
    echo "WARNING: Invalid complexity '$input', using default 2" >&2
    echo "2"
    return 0
  fi

  # Convert to integer (truncate decimals)
  local value=${input%.*}

  # Map to 1-4 range
  if [ "$value" -lt 30 ]; then
    echo "1"
  elif [ "$value" -lt 50 ]; then
    echo "2"
  elif [ "$value" -lt 70 ]; then
    echo "3"
  else
    echo "4"
  fi

  # Emit info message if normalization occurred
  if [ "$value" -lt 1 ] || [ "$value" -gt 4 ]; then
    echo "INFO: Normalized complexity $input → $(normalize_complexity "$input")" >&2
  fi
}
```

Integration in `sm_init`:
- Call `normalize_complexity` before validation
- Update validation to accept normalized values
- Emit INFO message when normalization occurs

**3. Graceful Degradation for State Machine**

Wrap state machine validation in error handling with fallback initialization:

```bash
# In sm_init, wrap validation with degraded initialization fallback
if ! validate_research_complexity "$research_complexity"; then
  echo "WARNING: Complexity validation failed, initializing with defaults" >&2
  research_complexity="2"  # Safe default
  # Continue with degraded initialization instead of failing
fi
```

Ensures STATE_FILE is always set even when metadata is imperfect.

### Testing Approach

**Unit Tests**:
- `test_error_context_detection.sh`: Verify `is_test_context` correctly identifies test workflows, /tmp scripts, and environment variables
- `test_complexity_normalization.sh`: Verify `normalize_complexity` maps values correctly (<30→1, 30-50→2, 50-70→3, ≥70→4)
- `test_state_machine_degradation.sh`: Verify STATE_FILE initialization succeeds even with invalid complexity

**Integration Tests**:
- `test_err_trap_test_suppression.sh`: Run /test command and verify no ERR trap errors logged for test framework failures
- `test_legacy_complexity_handling.sh`: Run /test with plan containing legacy complexity score (78.5) and verify successful execution

### Backward Compatibility

- ERR trap changes only affect test contexts (non-test workflows unchanged)
- Complexity normalization is additive (valid 1-4 values pass through unchanged)
- Graceful degradation only activates on validation failures (happy path unchanged)
- No changes to public APIs or function signatures

## Implementation Phases

### Phase 1: Add Test Context Detection to ERR Trap [COMPLETE]
dependencies: []

**Objective**: Modify error-handling.sh to detect test execution contexts and skip error logging for test framework errors

**Complexity**: Low

**Tasks**:
- [x] Add `is_test_context()` function to error-handling.sh (after line 200, in "Error Classification" section)
  - [x] Implement workflow ID pattern check (`WORKFLOW_ID` matches `^test_`)
  - [x] Implement script path check (caller script matches `/tmp/test_.*\.sh$`)
  - [x] Implement environment variable check (`SUPPRESS_ERR_LOGGING=1`)
  - [x] Return 0 if any condition matches, 1 otherwise
- [x] Integrate context detection in `_log_bash_exit` function (line ~1342)
  - [x] Call `is_test_context` before logging error
  - [x] Skip `log_command_error` call if test context detected
  - [x] Add debug message: "Skipping error log (test context detected)"
- [x] Integrate context detection in `_log_bash_error` function (line ~1360)
  - [x] Call `is_test_context` before logging error
  - [x] Skip `log_command_error` call if test context detected
  - [x] Add debug message: "Skipping error log (test context detected)"
- [x] Update error-handling.sh documentation
  - [x] Document test context detection behavior in header comments
  - [x] Add usage examples for `SUPPRESS_ERR_LOGGING` environment variable

**Testing**:
```bash
# Unit test: Verify test context detection
bash .claude/tests/unit/test_error_context_detection.sh

# Expected: All test context patterns correctly identified
# Expected: Non-test contexts correctly identified as non-test
```

**Expected Duration**: 1 hour

### Phase 2: Implement Complexity Score Normalization [COMPLETE]
dependencies: [1]

**Objective**: Add complexity score normalization to workflow-state-machine.sh to handle legacy and out-of-range complexity values

**Complexity**: Medium

**Tasks**:
- [x] Add `normalize_complexity()` function to workflow-state-machine.sh (after state enumeration section, line ~90)
  - [x] Validate numeric input (regex `^[0-9]+\.?[0-9]*$`)
  - [x] Return default "2" for invalid inputs with WARNING message
  - [x] Truncate decimals to integer (e.g., 78.5 → 78)
  - [x] Map to 1-4 range: <30→1, 30-50→2, 50-70→3, ≥70→4
  - [x] Emit INFO message when normalization occurs (value outside 1-4)
- [x] Integrate normalization in `sm_init` function (line ~421, before validation)
  - [x] Call `normalized_complexity=$(normalize_complexity "$research_complexity")`
  - [x] Replace `$research_complexity` with `$normalized_complexity` in validation
  - [x] Update error message to show original and normalized values if validation still fails
- [x] Update validation logic to accept normalized values (line 421-424)
  - [x] Keep existing validation for final sanity check
  - [x] Validation should always pass after normalization (defensive check only)
- [x] Update workflow-state-machine.sh documentation
  - [x] Document normalization behavior in header comments
  - [x] Add examples of legacy complexity score handling

**Testing**:
```bash
# Unit test: Verify complexity normalization
bash .claude/tests/unit/test_complexity_normalization.sh

# Expected: Legacy score 78.5 normalized to 4
# Expected: Valid scores 1-4 unchanged
# Expected: Invalid inputs default to 2 with warning
```

**Expected Duration**: 2 hours

### Phase 3: Add Graceful Degradation for State Machine Initialization [COMPLETE]
dependencies: [2]

**Objective**: Implement fallback initialization in workflow-state-machine.sh to ensure STATE_FILE is always set, even when validation fails

**Complexity**: Low

**Tasks**:
- [x] Wrap complexity validation in error handling (in `sm_init`, line ~421)
  - [x] Capture validation result in variable: `validation_result=0; validate_complexity || validation_result=$?`
  - [x] On validation failure (non-zero result):
    - [x] Log WARNING (not ERROR): "Complexity validation failed, using default"
    - [x] Set `research_complexity=2` (safe default)
    - [x] Continue initialization instead of returning 1
- [x] Ensure STATE_FILE initialization always executes (line ~450+)
  - [x] Move STATE_FILE initialization outside validation conditional
  - [x] Initialize STATE_FILE path before any validation
  - [x] Export STATE_FILE early to prevent "STATE_FILE not set" errors
- [x] Add validation recovery documentation
  - [x] Document fallback behavior in function header
  - [x] Add examples of degraded initialization scenarios
  - [x] Note that workflows proceed with default complexity=2

**Testing**:
```bash
# Unit test: Verify graceful degradation
bash .claude/tests/unit/test_state_machine_degradation.sh

# Expected: STATE_FILE initialized even with invalid complexity
# Expected: Warning message emitted but no fatal error
# Expected: Default complexity=2 used for degraded initialization
```

**Expected Duration**: 1 hour

### Phase 4: Integration Testing and Validation [COMPLETE]
dependencies: [1, 2, 3]

**Objective**: Verify end-to-end /test command workflow with error fixes and validate error log cleanup

**Complexity**: Medium

**Tasks**:
- [x] Create integration test for ERR trap suppression
  - [x] File: `.claude/tests/integration/test_err_trap_test_suppression.sh`
  - [x] Run /test command with plan that triggers test framework errors
  - [x] Verify no ERR trap errors logged to errors.jsonl for test contexts
  - [x] Verify real errors (non-test contexts) still logged correctly
- [x] Create integration test for legacy complexity handling
  - [x] File: `.claude/tests/integration/test_legacy_complexity_handling.sh`
  - [x] Create test plan with complexity score 78.5 in metadata
  - [x] Run /test command with this plan
  - [x] Verify STATE_FILE initialized successfully
  - [x] Verify complexity normalized to 4 with INFO message
  - [x] Verify no cascading "STATE_FILE not set" errors
- [x] Run full test suite to ensure no regressions
  - [x] Execute `.claude/tests/run_all_tests.sh`
  - [x] Verify all existing tests still pass
  - [x] Verify no new errors introduced
- [x] Validate error log cleanup
  - [x] Query errors.jsonl for /test command errors before fixes
  - [x] Note count of ERR trap false positives and state machine errors
  - [x] Re-run /test scenarios that previously failed
  - [x] Verify no new false positive errors logged

**Testing**:
```bash
# Run integration tests
bash .claude/tests/integration/test_err_trap_test_suppression.sh
bash .claude/tests/integration/test_legacy_complexity_handling.sh

# Run full test suite
bash .claude/tests/run_all_tests.sh

# Query error log for validation
bash .claude/scripts/query-errors.sh --command /test --since 1h
```

**Expected Duration**: 1-2 hours

### Phase 5: Update Error Log Status [COMPLETE]
dependencies: [4]

**Objective**: Update error log entries from FIX_PLANNED to RESOLVED

**Tasks**:
- [x] Verify all fixes are working (tests pass, no new errors generated)
- [x] Update error log entries to RESOLVED status:
  ```bash
  source .claude/lib/core/error-handling.sh
  RESOLVED_COUNT=$(mark_errors_resolved_for_plan "/home/benjamin/.config/.claude/specs/014_repair_test_20251202_100545/plans/001-repair-test-20251202-100545-plan.md")
  echo "Resolved $RESOLVED_COUNT error log entries"
  ```
- [x] Verify no FIX_PLANNED errors remain for this plan:
  ```bash
  REMAINING=$(query_errors --status FIX_PLANNED | jq -r '.repair_plan_path' | grep -c "014_repair_test_20251202_100545" || echo "0")
  [ "$REMAINING" -eq 0 ] && echo "All errors resolved" || echo "WARNING: $REMAINING errors still FIX_PLANNED"
  ```

**Testing**:
```bash
# Verify error log updated correctly
bash .claude/scripts/query-errors.sh --status RESOLVED | grep -c "014_repair_test_20251202_100545"

# Verify no FIX_PLANNED errors remain
bash .claude/scripts/query-errors.sh --status FIX_PLANNED | grep "014_repair_test_20251202_100545" || echo "None found (expected)"
```

**Expected Duration**: 30 minutes

## Testing Strategy

### Unit Test Coverage

**error-handling.sh changes**:
- `test_error_context_detection.sh`: Test `is_test_context` with various workflow IDs, script paths, and environment variables
  - Test case: WORKFLOW_ID="test_12345" → returns 0
  - Test case: BASH_SOURCE[2]="/tmp/test_foo.sh" → returns 0
  - Test case: SUPPRESS_ERR_LOGGING=1 → returns 0
  - Test case: Normal workflow → returns 1

**workflow-state-machine.sh changes**:
- `test_complexity_normalization.sh`: Test `normalize_complexity` with edge cases
  - Test case: 78.5 → "4"
  - Test case: 25 → "1"
  - Test case: 45 → "2"
  - Test case: 65 → "3"
  - Test case: "invalid" → "2" (with warning)
- `test_state_machine_degradation.sh`: Test graceful degradation
  - Test case: Invalid complexity → STATE_FILE still initialized
  - Test case: Missing complexity → defaults to 2
  - Test case: Validation failure → warning emitted, not error

### Integration Test Coverage

**End-to-end workflows**:
- `test_err_trap_test_suppression.sh`: Full /test command with test framework errors
  - Verify no false positive errors logged
  - Verify test execution succeeds
  - Verify error log remains clean
- `test_legacy_complexity_handling.sh`: /test with legacy complexity plan
  - Verify STATE_FILE initialization
  - Verify complexity normalization
  - Verify workflow completes successfully

### Coverage Target

- Minimum 90% line coverage for modified functions
- 100% branch coverage for error handling paths
- All integration tests must pass

## Documentation Requirements

### Code Documentation

- Add function header comments for `is_test_context()` and `normalize_complexity()`
- Document test context detection patterns in error-handling.sh header
- Document complexity normalization mapping in workflow-state-machine.sh header
- Add inline comments explaining degradation logic

### User-Facing Documentation

- No user-facing documentation updates required (internal bug fixes)
- Error log will be cleaner (fewer false positives) but no user action needed

### Standards Compliance

- All changes follow three-tier library sourcing pattern (already enforced in existing files)
- Error logging standards maintained (log_command_error usage preserved for real errors)
- Testing protocols followed (unit + integration tests required)
- Clean-break development applied (no deprecated compatibility layers)

## Dependencies

### External Dependencies
- None (all changes within existing .claude/lib/ libraries)

### Internal Dependencies
- error-handling.sh must be sourced by all commands (already enforced)
- workflow-state-machine.sh must be sourced by workflow commands (already enforced)
- errors.jsonl must exist (created by ensure_error_log_exists)

### File Modifications
- `/home/benjamin/.config/.claude/lib/core/error-handling.sh` (add test context detection)
- `/home/benjamin/.config/.claude/lib/workflow/workflow-state-machine.sh` (add complexity normalization and degradation)
- New test files in `.claude/tests/unit/` and `.claude/tests/integration/`

## Risk Mitigation

### Risk 1: Over-Suppression of Real Errors
- **Mitigation**: Test context detection uses specific patterns (test_* workflow IDs, /tmp/test_*.sh paths)
- **Validation**: Integration tests verify real errors still logged in non-test contexts

### Risk 2: Complexity Normalization Edge Cases
- **Mitigation**: Comprehensive unit tests cover all ranges and edge cases
- **Fallback**: Invalid inputs default to safe value (2) rather than failing

### Risk 3: State Machine Degradation Masking Real Issues
- **Mitigation**: Degradation only applies to complexity validation, not other validations
- **Logging**: WARNING messages emitted when degradation occurs for visibility

### Rollback Plan
- All changes are additive (no breaking changes to existing behavior)
- If issues discovered, remove `is_test_context` checks and `normalize_complexity` calls
- State files from before changes remain compatible (no schema changes)
