# Refactor /coordinate Command to Reduce Bash Complexity

## Metadata
- **Date**: 2025-11-05
- **Feature**: Simplify /coordinate command bash orchestration
- **Scope**: Eliminate 195 lines (9%) of bash workaround overhead while maintaining all functionality
- **Estimated Phases**: 6
- **Complexity**: High (7.5/10)
- **Estimated Total Time**: 10-14 hours
- **Standards File**: /home/benjamin/.config/CLAUDE.md
- **Research Reports**: Internal research (agent analysis of bash issues)

## Overview

The `/coordinate` command currently contains 195 lines (9% of 2,212 total lines) of bash workaround code to handle three fundamental limitations:

1. **Export Persistence Issue** (GitHub #334, #2508): Environment variables don't persist between separate Bash tool invocations
2. **Array Export Limitation**: Bash arrays cannot be exported across process boundaries
3. **Code Transformation Threshold**: Bash blocks >400 lines trigger automatic transformation that breaks variable expansion

### Current Impact
- **CLAUDE_PROJECT_DIR recalculated**: 3 times (90 lines)
- **Array workarounds**: REPORT_PATH_N variables pattern (35 lines)
- **Library re-sourcing**: 3x duplication in Phase 0 alone (50 lines)
- **Performance overhead**: ~150ms from redundant git operations
- **Maintenance burden**: Complex patterns requiring expert knowledge

### Goals
1. **Reduce complexity**: Eliminate or simplify workarounds where possible
2. **Improve readability**: Make code understandable without deep bash expertise
3. **Maintain functionality**: Zero regressions in workflow behavior
4. **Consider alternatives**: Evaluate if bash is the right tool for orchestration
5. **Document constraints**: Make limitations explicit and clear

## Success Criteria
- [ ] Bash workaround overhead reduced from 195 lines to <100 lines (≥50% reduction)
- [ ] No functional regressions (all 4 workflow types work identically)
- [ ] Improved readability (code review from non-bash-expert passes)
- [ ] Better error messages (failures are easier to diagnose)
- [ ] Documentation updated (limitations are explicit)
- [ ] All tests pass (existing test suite + new regression tests)

## Risk Assessment

### High Risks
- **Breaking existing workflows**: Many users depend on /coordinate
  - *Mitigation*: Comprehensive testing, phased rollout, backup original

- **Introducing subtle bugs**: State management is complex
  - *Mitigation*: Extensive test coverage, checkpoint validation

### Medium Risks
- **Performance regression**: Alternative approaches may be slower
  - *Mitigation*: Benchmark before/after, set performance baseline

- **Maintenance burden shift**: New approach may have different complexities
  - *Mitigation*: Document trade-offs, ensure team understanding

### Low Risks
- **Documentation drift**: Updated code may not match docs
  - *Mitigation*: Update docs in same phase as code changes

## Technical Design

### Problem Analysis

The core issue is **architectural mismatch**: `/coordinate` needs stateful orchestration, but the Bash tool provides isolated invocations.

#### Current Architecture (Flawed)
```
┌─────────────────────────────────────────────────────┐
│ /coordinate command                                  │
│                                                      │
│  ┌──────────┐    ┌──────────┐    ┌──────────┐     │
│  │ Block 1  │───▶│ Block 2  │───▶│ Block 3  │     │
│  │ (export) │    │ (lost!)  │    │ (lost!)  │     │
│  └──────────┘    └──────────┘    └──────────┘     │
│       │               │               │             │
│       └───────────────┴───────────────┘             │
│       Workarounds: Recalculate state 3x             │
└─────────────────────────────────────────────────────┘
```

#### Constraint Analysis

| Constraint | Type | Can Change? | Impact |
|------------|------|-------------|---------|
| Export persistence | Tool limitation | No (Anthropic) | Must work around |
| Array export | Bash limitation | No (language) | Must work around |
| 400-line threshold | Tool behavior | No (Anthropic) | Must split blocks |
| Bash as language | Design choice | **Yes** | **Can reconsider** |

### Evaluated Approaches

#### Approach A: State File Pattern (Recommended)

**Concept**: Store all paths in a simple state file after Phase 0, read at start of each subsequent phase.

**Implementation**:
```bash
# Phase 0: Calculate and persist
cat > "$STATE_FILE" <<EOF
CLAUDE_PROJECT_DIR=$CLAUDE_PROJECT_DIR
TOPIC_PATH=$TOPIC_PATH
PLAN_PATH=$PLAN_PATH
REPORT_PATH_1=$REPORT_PATH_1
REPORT_PATH_2=$REPORT_PATH_2
...
EOF

# Phase 1+: Source state file
source "$STATE_FILE"
# All variables now available
```

**Pros**:
- ✅ Eliminates 90% of recalculation code
- ✅ Simple to understand (file is "database")
- ✅ No export/array issues
- ✅ Easy to debug (inspect state file)
- ✅ Atomic operations (write-rename pattern)

**Cons**:
- ❌ File I/O overhead (~5ms per read/write)
- ❌ Cleanup needed (on success/failure)
- ❌ Race conditions if multiple /coordinate instances

**Complexity Reduction**: 195 lines → ~40 lines (79% reduction)

---

#### Approach B: JSON State File

**Concept**: Like Approach A, but use JSON for structured data.

**Implementation**:
```bash
# Phase 0: Write JSON
cat > "$STATE_FILE" <<EOF
{
  "project_dir": "$CLAUDE_PROJECT_DIR",
  "topic_path": "$TOPIC_PATH",
  "report_paths": ["$R1", "$R2", "$R3"]
}
EOF

# Phase 1+: Parse JSON with jq
TOPIC_PATH=$(jq -r '.topic_path' "$STATE_FILE")
```

**Pros**:
- ✅ Structured data (better for arrays)
- ✅ Easier to extend
- ✅ Better validation (jq validates JSON)

**Cons**:
- ❌ Requires `jq` dependency
- ❌ More complex parsing
- ❌ Slower than bash source (~15ms vs ~5ms)

**Complexity Reduction**: 195 lines → ~60 lines (69% reduction)

---

#### Approach C: Single Library Initialization Function

**Concept**: Consolidate all initialization into one library function that can be called from each block.

**Implementation**:
```bash
# .claude/lib/phase-init.sh
initialize_phase() {
  local phase="$1"

  # Detect project dir (once per block, but encapsulated)
  detect_project_dir

  # Source required libraries
  source_libraries "$phase"

  # Load state file if exists
  [ -f "$STATE_FILE" ] && source "$STATE_FILE"
}

# Each phase block:
source .claude/lib/phase-init.sh
initialize_phase "1"
```

**Pros**:
- ✅ Encapsulates initialization complexity
- ✅ DRY principle (single function)
- ✅ Easy to maintain

**Cons**:
- ❌ Still has recalculation overhead
- ❌ Doesn't solve root cause
- ❌ Library needs recalculation logic

**Complexity Reduction**: 195 lines → ~120 lines (38% reduction)

---

#### Approach D: Hybrid Python Orchestrator

**Concept**: Use Python for orchestration logic, bash only for verification.

**Implementation**:
```python
# .claude/lib/coordinate_orchestrator.py
class WorkflowOrchestrator:
    def __init__(self, description):
        self.paths = self.calculate_all_paths(description)

    def run_phase_1(self):
        # Invoke agents with paths from self.paths
        # Run verification bash script
```

**Pros**:
- ✅ Eliminates all bash limitations
- ✅ Better data structures (dicts, lists)
- ✅ Easier testing
- ✅ Modern error handling

**Cons**:
- ❌ Architectural change (major refactor)
- ❌ Python dependency
- ❌ Different debugging model
- ❌ Team may not know Python

**Complexity Reduction**: 195 lines → ~0 bash workaround lines (100%)
**New Complexity**: ~300 lines Python code

---

### Recommended Approach: **Approach A (State File Pattern)**

**Rationale**:
1. **Highest complexity reduction** (79%) with lowest risk
2. **Stays within bash** (team familiarity, no new dependencies)
3. **Simple mental model** (file is the source of truth)
4. **Easy to debug** (inspect state file directly)
5. **Performance acceptable** (~5ms overhead per phase)

**Trade-offs Accepted**:
- Small file I/O overhead (negligible compared to agent invocations)
- Cleanup logic needed (but already have checkpoint cleanup patterns)
- State file is implementation detail (not user-visible)

### Detailed Design: State File Implementation

#### State File Format
```bash
# .claude/data/state/coordinate_${WORKFLOW_ID}.env
# Auto-generated by Phase 0 - Do not edit manually

# Project metadata
CLAUDE_PROJECT_DIR=/home/benjamin/.config
SPECS_ROOT=/home/benjamin/.config/.claude/specs
TOPIC_NUM=596
TOPIC_NAME=refactor_coordinate_command
TOPIC_PATH=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command

# Workflow metadata
WORKFLOW_SCOPE=research-and-plan
WORKFLOW_DESCRIPTION="research and plan coordinate refactor"
RESEARCH_COMPLEXITY=3

# Phase 0 paths (pre-calculated)
RESEARCH_SUBDIR=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command/reports
PLAN_PATH=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command/plans/001_implementation.md
IMPL_ARTIFACTS=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command/artifacts
DEBUG_REPORT=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command/debug/001_debug_analysis.md
SUMMARY_PATH=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command/summaries/596_refactor_coordinate_command_summary.md

# Research report paths (max 4)
REPORT_PATH_1=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command/reports/001_topic1.md
REPORT_PATH_2=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command/reports/002_topic2.md
REPORT_PATH_3=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command/reports/003_topic3.md
REPORT_PATH_4=/home/benjamin/.config/.claude/specs/596_refactor_coordinate_command/reports/004_topic4.md

# Tracking variables
SUCCESSFUL_REPORT_COUNT=0
TESTS_PASSING=unknown
IMPLEMENTATION_OCCURRED=false
OVERVIEW_PATH=
```

#### State File Location
- **Path**: `.claude/data/state/coordinate_${WORKFLOW_ID}.env`
- **WORKFLOW_ID**: `${TOPIC_NUM}_${TIMESTAMP}` (e.g., `596_20251105_001447`)
- **Lifecycle**: Created in Phase 0, deleted on workflow completion or error
- **Permissions**: 600 (read/write by owner only)

#### State File Operations

**Write Operation** (Phase 0 only):
```bash
write_state_file() {
  local state_file="$1"
  local tmp_file="${state_file}.tmp.$$"

  # Write to temporary file
  cat > "$tmp_file" <<EOF
# Auto-generated state - do not edit
CLAUDE_PROJECT_DIR=$CLAUDE_PROJECT_DIR
...
EOF

  # Atomic rename
  mv "$tmp_file" "$state_file"
  chmod 600 "$state_file"
}
```

**Read Operation** (Phase 1+):
```bash
load_state_file() {
  local state_file="$1"

  if [ ! -f "$state_file" ]; then
    echo "ERROR: State file not found: $state_file" >&2
    echo "Phase 0 may have failed to complete." >&2
    return 1
  fi

  # Source the state file
  source "$state_file"

  # Validate critical variables
  if [ -z "$TOPIC_PATH" ] || [ -z "$CLAUDE_PROJECT_DIR" ]; then
    echo "ERROR: State file corrupted or incomplete" >&2
    return 1
  fi
}
```

**Cleanup Operation** (Workflow end):
```bash
cleanup_state_file() {
  local state_file="$1"
  [ -f "$state_file" ] && rm -f "$state_file"
}
```

#### Integration Points

**Phase 0 Changes**:
```diff
# Phase 0: Block 3 (after path calculation)
+ # Write state file for subsequent phases
+ STATE_FILE=".claude/data/state/coordinate_${TOPIC_NUM}_$(date +%Y%m%d_%H%M%S).env"
+ write_state_file "$STATE_FILE"
+ export STATE_FILE

# No more: export TOPIC_PATH, export PLAN_PATH, etc.
```

**Phase 1+ Changes**:
```diff
# Each subsequent phase
- # Recalculate CLAUDE_PROJECT_DIR (30 lines)
- if [ -z "${CLAUDE_PROJECT_DIR:-}" ]; then
-   ...
- fi

+ # Load state file (3 lines)
+ source .claude/lib/state-file-utils.sh
+ load_state_file "$STATE_FILE"

# All variables now available from state file
```

#### Error Handling

**State File Missing**:
```bash
if ! load_state_file "$STATE_FILE"; then
  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
  echo "CRITICAL ERROR: Workflow State Not Found"
  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
  echo ""
  echo "Expected state file: $STATE_FILE"
  echo ""
  echo "Possible causes:"
  echo "  1. Phase 0 did not complete successfully"
  echo "  2. State file was manually deleted"
  echo "  3. Concurrent workflow conflict"
  echo ""
  echo "Diagnostic commands:"
  echo "  ls -la .claude/data/state/"
  echo "  cat .claude/data/logs/coordinate*.log | tail -50"
  echo ""
  exit 1
fi
```

**State File Corrupted**:
```bash
# Validation after sourcing
required_vars=(CLAUDE_PROJECT_DIR TOPIC_PATH PLAN_PATH WORKFLOW_SCOPE)
missing_vars=()

for var in "${required_vars[@]}"; do
  if [ -z "${!var}" ]; then
    missing_vars+=("$var")
  fi
done

if [ ${#missing_vars[@]} -gt 0 ]; then
  echo "ERROR: State file validation failed" >&2
  echo "Missing variables: ${missing_vars[*]}" >&2
  echo "State file may be corrupted." >&2
  exit 1
fi
```

#### Concurrent Workflow Handling

**Problem**: Two `/coordinate` invocations could conflict.

**Solution**: Workflow ID includes timestamp, making state files unique:
- Workflow 1: `coordinate_596_20251105_001447.env`
- Workflow 2: `coordinate_597_20251105_001523.env`

Each workflow has its own state file, no conflicts.

### Alternative: Mutex Lock Pattern (Optional Enhancement)

If we want to prevent concurrent /coordinate invocations entirely:

```bash
# Phase 0: Acquire lock
LOCK_FILE=".claude/data/locks/coordinate.lock"
LOCK_FD=200

acquire_lock() {
  exec 200>"$LOCK_FILE"
  if ! flock -n 200; then
    echo "ERROR: Another /coordinate workflow is running" >&2
    echo "Wait for completion or remove: $LOCK_FILE" >&2
    exit 1
  fi
}

release_lock() {
  flock -u 200
  rm -f "$LOCK_FILE"
}

trap release_lock EXIT
acquire_lock
```

**Decision**: Not implementing lock pattern initially (YAGNI - You Aren't Gonna Need It). State files are isolated by workflow ID, concurrent workflows shouldn't interfere.

## Implementation Phases

### Phase 1: Create State File Infrastructure
**Objective**: Build the state file library and update workflow-initialization.sh to write state files
**Complexity**: Low (3/10)
**Estimated Time**: 1-2 hours

Tasks:
- [ ] Create `.claude/lib/state-file-utils.sh` library with functions:
  - `write_state_file()` - Write state to file atomically
  - `load_state_file()` - Source state file with validation
  - `cleanup_state_file()` - Remove state file
  - `validate_state_file()` - Check required variables present
- [ ] Create `.claude/data/state/` directory with `.gitignore` (state files are transient)
- [ ] Update `workflow-initialization.sh:initialize_workflow_paths()` to call `write_state_file()`
- [ ] Add state file path export: `export STATE_FILE=...`
- [ ] Add error handling for state file write failures

Testing:
```bash
# Test state file creation
cd /home/benjamin/.config
source .claude/lib/state-file-utils.sh
source .claude/lib/workflow-initialization.sh

# Simulate Phase 0
initialize_workflow_paths "test workflow" "research-and-plan"

# Verify state file created
ls -la .claude/data/state/
cat .claude/data/state/coordinate_*.env | head -20

# Verify all required variables present
source .claude/data/state/coordinate_*.env
echo "TOPIC_PATH=$TOPIC_PATH"
echo "PLAN_PATH=$PLAN_PATH"

# Cleanup
rm .claude/data/state/coordinate_*.env
```

Files Modified:
- `.claude/lib/state-file-utils.sh` (new file, ~150 lines)
- `.claude/lib/workflow-initialization.sh` (add 10 lines at end of `initialize_workflow_paths()`)
- `.claude/data/state/.gitignore` (new file, 2 lines: `*`, `!.gitignore`)

Dependencies:
- None (pure bash implementation)

---

### Phase 2: Refactor Phase 0 to Use State File
**Objective**: Remove recalculation code from coordinate.md Phase 0 Blocks 2-3
**Complexity**: Medium (5/10)
**Estimated Time**: 2-3 hours

Tasks:
- [ ] Remove CLAUDE_PROJECT_DIR recalculation from Block 2 (lines 721-731)
- [ ] Remove CLAUDE_PROJECT_DIR recalculation from Block 3 (lines 915-921)
- [ ] Add `load_state_file()` call at start of Block 2
- [ ] Add `load_state_file()` call at start of Block 3
- [ ] Remove `reconstruct_report_paths_array()` function (no longer needed)
- [ ] Remove export commands for path variables (state file handles this)
- [ ] Verify Block 1 still exports STATE_FILE variable
- [ ] Update comments to reference state file pattern

Testing:
```bash
# Backup original
cp .claude/commands/coordinate.md .claude/commands/coordinate.md.backup-phase2

# Test Phase 0 execution
/coordinate "test state file integration"

# Verify state file created after Phase 0
ls -la .claude/data/state/

# Verify Phase 0 completes without errors
# (workflow will continue to Phase 1, can interrupt)

# Check for any unbound variable errors
grep -i "unbound variable" ~/.claude.log || echo "No unbound variable errors"

# Restore if issues found
# cp .claude/commands/coordinate.md.backup-phase2 .claude/commands/coordinate.md
```

Files Modified:
- `.claude/commands/coordinate.md` (Phase 0 sections, reduce ~60 lines)

Success Criteria:
- [ ] Phase 0 Block 2 no longer recalculates CLAUDE_PROJECT_DIR
- [ ] Phase 0 Block 3 no longer recalculates CLAUDE_PROJECT_DIR
- [ ] All variables available in Block 2/3 via state file
- [ ] No unbound variable errors during execution

---

### Phase 3: Refactor Phase 1 (Research) to Use State File
**Objective**: Simplify Phase 1 bash blocks by loading state instead of recalculating
**Complexity**: Medium (5/10)
**Estimated Time**: 2-3 hours

Tasks:
- [ ] Replace CLAUDE_PROJECT_DIR recalculation in Phase 1 blocks
- [ ] Replace library sourcing with load_state_file() call
- [ ] Remove array reconstruction code (use REPORT_PATH_N variables directly)
- [ ] Simplify verification block (state file has all paths)
- [ ] Update SUCCESSFUL_REPORT_PATHS tracking (append to state file or keep in bash)
- [ ] Test research agent invocation with paths from state file
- [ ] Test verification checkpoint with state file paths

Testing:
```bash
# Create minimal test workflow
/coordinate "research bash state file patterns"

# Monitor Phase 1 execution
# - Should invoke 2-3 research agents
# - Should verify reports created
# - Should complete without errors

# Verify state file updated with successful reports
cat .claude/data/state/coordinate_*.env | grep SUCCESSFUL

# Check logs for any issues
tail -50 ~/.claude.log | grep -i "error\|warning"
```

Files Modified:
- `.claude/commands/coordinate.md` (Phase 1 sections, reduce ~40 lines)

Success Criteria:
- [ ] Phase 1 loads all paths from state file
- [ ] No recalculation of CLAUDE_PROJECT_DIR
- [ ] Research agents receive correct paths
- [ ] Verification checkpoint works correctly
- [ ] State file updated with successful report count

---

### Phase 4: Refactor Phases 2-6 to Use State File
**Objective**: Apply state file pattern to planning, implementation, testing, debug, and documentation phases
**Complexity**: Medium (6/10)
**Estimated Time**: 3-4 hours

Tasks:
- [ ] **Phase 2 (Planning)**: Replace recalculation with load_state_file()
- [ ] **Phase 3 (Implementation)**: Simplify state loading for wave-based execution
- [ ] **Phase 4 (Testing)**: Load state file for test execution
- [ ] **Phase 5 (Debug)**: Load state file for debug iteration loop
- [ ] **Phase 6 (Documentation)**: Load state file for summary creation
- [ ] Remove all remaining CLAUDE_PROJECT_DIR recalculation blocks
- [ ] Remove all remaining library re-sourcing duplication
- [ ] Update state file during phase execution (e.g., TESTS_PASSING flag)
- [ ] Add state file cleanup on workflow completion

Testing:
```bash
# Test research-and-plan workflow (Phases 0-2)
/coordinate "research authentication to create plan"
# Verify: completes successfully, state file cleaned up

# Test full-implementation workflow (Phases 0-4,6)
/coordinate "implement simple test feature"
# Verify: all phases load state correctly

# Test debug-only workflow (Phases 0,1,5)
/coordinate "debug coordinate state file issue"
# Verify: debug phase has access to all paths

# Verify state file cleanup
ls -la .claude/data/state/
# Should be empty after successful workflows
```

Files Modified:
- `.claude/commands/coordinate.md` (Phases 2-6, reduce ~95 lines total)
- `.claude/lib/state-file-utils.sh` (add state update functions if needed)

Success Criteria:
- [ ] All phases load state file successfully
- [ ] No recalculation code remains (except Phase 0)
- [ ] State file cleanup works on success
- [ ] State file cleanup works on error (via trap)
- [ ] All 4 workflow types work correctly

---

### Phase 5: Comprehensive Testing and Validation
**Objective**: Ensure no regressions in any workflow type or error condition
**Complexity**: High (7/10)
**Estimated Time**: 2-3 hours

Tasks:
- [ ] **Test 1**: Research-only workflow (`/coordinate "research X"`)
  - Verify: 2-4 reports created, no plan, state cleaned up
- [ ] **Test 2**: Research-and-plan workflow (`/coordinate "research X to plan Y"`)
  - Verify: reports + plan created, state cleaned up
- [ ] **Test 3**: Full-implementation workflow (`/coordinate "implement X"`)
  - Verify: reports + plan + implementation + summary, state cleaned up
- [ ] **Test 4**: Debug-only workflow (`/coordinate "fix bug X"`)
  - Verify: reports + debug analysis, state cleaned up
- [ ] **Test 5**: Error in Phase 0 (missing library)
  - Verify: Clear error message, no state file created
- [ ] **Test 6**: Error in Phase 1 (agent fails)
  - Verify: State file exists, clear error, cleanup on exit
- [ ] **Test 7**: Checkpoint resume
  - Verify: State file reloaded correctly, workflow resumes
- [ ] **Test 8**: Concurrent workflows
  - Verify: Two workflows don't interfere (different state files)
- [ ] Create automated test suite in `.claude/tests/test_coordinate_state_file.sh`
- [ ] Run full regression test suite
- [ ] Performance comparison: before vs after (should be equivalent ±50ms)

Testing Script:
```bash
#!/usr/bin/env bash
# .claude/tests/test_coordinate_state_file.sh

test_research_only() {
  /coordinate "research state file patterns" 2>&1 | tee test1.log
  grep -q "Workflow complete: research-only" test1.log
  [ ! -f .claude/data/state/coordinate_*.env ]  # State cleaned up
}

test_research_and_plan() {
  /coordinate "research auth to create plan" 2>&1 | tee test2.log
  grep -q "Workflow complete: research-and-plan" test2.log
  [ ! -f .claude/data/state/coordinate_*.env ]
}

test_state_file_error_handling() {
  # Manually corrupt state file mid-workflow
  # Verify clear error message
}

run_all_tests
```

Success Criteria:
- [ ] All 8 test scenarios pass
- [ ] No unbound variable errors
- [ ] No state file leaks (all cleaned up)
- [ ] Performance within ±50ms of baseline
- [ ] Error messages are clear and actionable

---

### Phase 6: Documentation and Cleanup
**Objective**: Update documentation and remove old workaround patterns
**Complexity**: Low (3/10)
**Estimated Time**: 1-2 hours

Tasks:
- [ ] Update `/coordinate` command documentation:
  - Add "State File Pattern" section explaining the approach
  - Document state file location and lifecycle
  - Update "Available Utility Functions" to include state-file-utils.sh
  - Remove references to export workarounds
- [ ] Update `CLAUDE.md`:
  - Document state file pattern in orchestration section
  - Note bash limitations explicitly
  - Add state file pattern to quick reference
- [ ] Update `.claude/lib/README.md`:
  - Add state-file-utils.sh to library catalog
  - Document when to use state files vs exports
- [ ] Create `.claude/docs/concepts/state-file-pattern.md`:
  - Explain why state files solve export persistence issue
  - Provide examples and best practices
  - Document cleanup and error handling patterns
- [ ] Remove backup files created during refactor
- [ ] Remove deprecated functions from workflow-initialization.sh:
  - `reconstruct_report_paths_array()` (no longer needed)
- [ ] Update git commit messages and create summary

Documentation Structure:
```markdown
# State File Pattern

## Problem
Bash tool invocations are isolated - exports don't persist between blocks.

## Solution
Write all calculated state to a file in Phase 0, source it in subsequent phases.

## Benefits
- Eliminates 195 lines of recalculation code (79% reduction)
- Simpler mental model (file is source of truth)
- Easy to debug (inspect state file)
- No export or array issues

## Usage
[Code examples]

## Trade-offs
[File I/O overhead, cleanup needed]
```

Files Modified:
- `.claude/commands/coordinate.md` (documentation sections)
- `CLAUDE.md` (orchestration section)
- `.claude/lib/README.md` (library catalog)
- `.claude/docs/concepts/state-file-pattern.md` (new file)

Success Criteria:
- [ ] All documentation accurate and complete
- [ ] State file pattern explained clearly
- [ ] Examples are working and tested
- [ ] No references to old workaround patterns
- [ ] Code and docs are synchronized

---

## Testing Strategy

### Unit Tests
- **state-file-utils.sh functions**: Test each function independently
  - `write_state_file()`: Atomic writes, error handling
  - `load_state_file()`: Missing file, corrupted file, validation
  - `cleanup_state_file()`: Idempotent cleanup

### Integration Tests
- **Workflow execution**: All 4 workflow types (research-only, research-and-plan, full-implementation, debug-only)
- **Error scenarios**: Phase failures, missing libraries, agent failures
- **Checkpoint resume**: State file persists correctly for resume
- **Concurrent workflows**: No interference between workflows

### Regression Tests
- **Existing test suite**: `.claude/tests/test_*.sh` must all pass
- **Manual testing**: Run real workflows and verify outputs
- **Performance testing**: Benchmark before/after, ensure no significant slowdown

### Test Coverage Target
- ≥80% coverage for state-file-utils.sh functions
- 100% coverage for all 4 workflow types
- 100% coverage for error scenarios

## Performance Benchmarks

### Baseline (Current Implementation)
```bash
# Measure current performance
time /coordinate "research test feature to create plan"
# Baseline: ~X seconds (to be measured in Phase 5)
```

### Expected Performance (After Refactor)
- **State file overhead**: +5-10ms per phase (6 phases = +30-60ms total)
- **Saved git operations**: -150ms (3 redundant git calls eliminated)
- **Net change**: -90 to -120ms (faster)

### Acceptance Criteria
Performance must be within **±100ms** of baseline (accounting for variance).

## Documentation Requirements

### User-Facing Documentation
- [ ] `/coordinate` command reference updated
- [ ] State file pattern documented in CLAUDE.md
- [ ] Error messages reference state file concepts

### Developer Documentation
- [ ] State file pattern concept doc created
- [ ] Library API reference updated
- [ ] Code comments explain state file usage

### Migration Guide
Not needed - refactor is internal, no user-facing API changes.

## Dependencies

### Required Libraries (Already Exist)
- `.claude/lib/workflow-initialization.sh`
- `.claude/lib/verification-helpers.sh`
- `.claude/lib/unified-logger.sh`

### New Libraries (Created in Phase 1)
- `.claude/lib/state-file-utils.sh`

### External Dependencies
- None (pure bash implementation)

## Rollback Plan

If critical issues are discovered post-deployment:

1. **Immediate Rollback**:
   ```bash
   git revert HEAD  # Revert the refactor commit
   ```

2. **Preserve State Files** (for debugging):
   ```bash
   cp -r .claude/data/state .claude/data/state.backup
   ```

3. **Notify Users**:
   - Update CLAUDE.md with rollback notice
   - Investigate issues from preserved state files

4. **Root Cause Analysis**:
   - Analyze state files that caused issues
   - Determine if bug or design flaw
   - Fix and re-deploy or abandon approach

## Notes

### Why State File Over JSON?
**Decision**: Use bash-sourceable format (KEY=VALUE) instead of JSON.

**Rationale**:
- Simpler (no jq dependency)
- Faster (source vs parse, 5ms vs 15ms)
- Bash-native (no impedance mismatch)
- Sufficient for flat key-value data

### Why Not Python Orchestration?
**Decision**: Stay with bash for now.

**Rationale**:
- State file pattern solves 80% of the problem
- Python refactor is much larger effort (300+ lines new code)
- Team familiarity with bash
- Can reconsider if state file pattern proves insufficient

### Trade-offs Accepted
1. **File I/O overhead** (~5-10ms per phase): Acceptable given agent invocations are seconds
2. **Cleanup logic** needed: Already have checkpoint cleanup patterns to follow
3. **State file is implementation detail**: Users don't see it, low impact if it fails

### Future Enhancements (Out of Scope)
- **Mutex lock pattern**: Prevent concurrent workflows (YAGNI for now)
- **State file versioning**: Handle breaking changes (not needed yet)
- **State file encryption**: Sensitive data protection (no sensitive data currently)
- **State file compression**: Reduce disk usage (files are small, ~2KB)

## Complexity Analysis

### Phase Complexity Breakdown
| Phase | Complexity | Risk | Time | Reason |
|-------|-----------|------|------|---------|
| 1 | Low (3/10) | Low | 1-2h | New library, no refactor |
| 2 | Med (5/10) | Med | 2-3h | Phase 0 is critical path |
| 3 | Med (5/10) | Med | 2-3h | Phase 1 has agent invocations |
| 4 | Med (6/10) | Med | 3-4h | 5 phases to refactor |
| 5 | High (7/10) | High | 2-3h | Comprehensive testing needed |
| 6 | Low (3/10) | Low | 1-2h | Documentation only |

**Overall Complexity**: 7.5/10 (High)
- Requires deep understanding of bash limitations
- Critical path (Phase 0) must work perfectly
- Multiple phases to coordinate
- High test coverage required

### Risk Mitigation Summary
- **Backup files** before each phase
- **Incremental testing** after each phase
- **Rollback plan** documented
- **State file validation** catches corruption early
- **Error messages** provide clear diagnostics

## Estimated Time Summary
- Phase 1: 1-2 hours
- Phase 2: 2-3 hours
- Phase 3: 2-3 hours
- Phase 4: 3-4 hours
- Phase 5: 2-3 hours
- Phase 6: 1-2 hours

**Total**: 10-14 hours

**Assumptions**:
- Developer has deep bash knowledge
- No unexpected issues discovered
- Test suite execution is automated
- Documentation updates are straightforward
